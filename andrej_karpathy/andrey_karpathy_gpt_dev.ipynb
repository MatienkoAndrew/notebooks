{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbdNpaQdnuIa5GphLQZHKd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatienkoAndrew/notebooks/blob/main/andrey_karpathy_gpt_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FUNC"
      ],
      "metadata": {
        "id": "jg6iwOTa_ZXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def save(bigram_code: str, FILENAME: str):\n",
        "    with open(FILENAME, 'w') as file:\n",
        "        file.write(bigram_code)\n",
        "        print(f\"Saved file at: {os.path.abspath(FILENAME)}\")"
      ],
      "metadata": {
        "id": "us7ZaaMI_Y77"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download file"
      ],
      "metadata": {
        "id": "rQBUfYkkeU6w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5oxR71tc4S7",
        "outputId": "e90ffead-856f-40b0-eddd-c90f0a9174a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-17 16:00:48--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-03-17 16:00:48 (55.4 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ! wget https://github.com/karpathy/ng-video-lecture/blob/master/input.txt\n",
        "! wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read file"
      ],
      "metadata": {
        "id": "DVurQtaVeduQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read it to inspect it\n",
        "with open('input.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()"
      ],
      "metadata": {
        "id": "uNhnoJkkfFLA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"length of dataset in characters is {len(text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9Xro8AHfgXj",
        "outputId": "b738675d-232d-47ab-b4df-e3fd3f22290c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters is 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##-- first 1000 chatacters\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA-nCtvMfnrJ",
        "outputId": "2e32e972-927a-4943-8123-29f50f9ff262"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## all the unique character that occur in this text"
      ],
      "metadata": {
        "id": "7rCJplRuejPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here all the unique character that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEYvTGPxfq3f",
        "outputId": "1f7691c6-f6cc-4656-be4b-8c2388e95a26"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create mapping from characters to integers"
      ],
      "metadata": {
        "id": "ALpS7NaPelh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##-- create mapping from characters to integers\n",
        "stoi = { ch: i for i, ch in enumerate(chars) }\n",
        "atoi = { i: ch for i, ch in enumerate(chars) }\n",
        "\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([atoi[i] for i in l])\n",
        "print(encode(\"hi there\")) ##-- encoder: take a string, output a list of integers\n",
        "print(decode(encode('hi there'))) ##-- decoder: take a list of integers, output a string"
      ],
      "metadata": {
        "id": "tCN-Mb5Dg2JH",
        "outputId": "93de95e9-efc2-418d-e485-6fcd19da14f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 1, 58, 46, 43, 56, 43]\n",
            "hi there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## encode the entire text dataset"
      ],
      "metadata": {
        "id": "mLFGFzgUfPFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##-- let's encode the entire text dataset and store it into a torch.Tensor\n",
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "id": "UrHmQopLhsV3",
        "outputId": "c492b712-c5bf-4c7f-977d-72b19341dad1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train_test_split"
      ],
      "metadata": {
        "id": "2W1bdE72fjRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##-- train test split\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "print(f\"len(train_data)={len(train_data)}\")\n",
        "print(f\"len(val_data)={len(val_data)}\")"
      ],
      "metadata": {
        "id": "cIJmvLIShz7f",
        "outputId": "922abae6-c9a2-40e0-b885-a341c89e2168",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train_data)=1003854\n",
            "len(val_data)=111540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Block size"
      ],
      "metadata": {
        "id": "syGVbOdXh3D2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель обучается не на всем блоке данных (это было бы слишком трудозатратно), а на частях данных (чанках)\n",
        "\n",
        "Возьмем размер блока в 8 символов. На самом деле, в этот блок \"вшито\" 8 примеров.\n",
        "\n",
        "Трансформер учится делать предсказание для каждой позиции (2 ячейка)"
      ],
      "metadata": {
        "id": "cyWk0vGskNw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "id": "loOFL8N5jjf1",
        "outputId": "97babfb1-3e54-4b48-dce0-3473428155b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1: block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "id": "LX-bgod3jnC_",
        "outputId": "2e4f8585-0ea9-4466-8007-8bb0ab50a7b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([18]) the target: 47\n",
            "when input is tensor([18, 47]) the target: 56\n",
            "when input is tensor([18, 47, 56]) the target: 57\n",
            "when input is tensor([18, 47, 56, 57]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "У нас есть одно измерение - поданное предложение\n",
        "\n",
        "Есть еще одно - батч\n",
        "\n",
        "В модель подается партия предложений (батч), которая складывается в один тензор (для ускорения работы)\n"
      ],
      "metadata": {
        "id": "T8UNw9NvkEGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
        "block_size = 8 ##-- максимальная длина предложения (в нашем случае, количество символов)\n",
        "\n",
        "def get_batch(split: str='train'):\n",
        "    '''\n",
        "    generate a small batch of data of inputs x and targets y\n",
        "\n",
        "    split: str: train or test\n",
        "    '''\n",
        "    data = train_data if split=='train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size, )) ##-- random idx\n",
        "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
        "    return (x, y)\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size):\n",
        "    for t in range(block_size):\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b, t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "id": "g7sUCL-il8MP",
        "outputId": "5023905f-6531-491e-d902-27ced98e78f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
            "----\n",
            "when input is [24] the target: 43\n",
            "when input is [24, 43] the target: 58\n",
            "when input is [24, 43, 58] the target: 5\n",
            "when input is [24, 43, 58, 5] the target: 57\n",
            "when input is [24, 43, 58, 5, 57] the target: 1\n",
            "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
            "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
            "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
            "when input is [44] the target: 53\n",
            "when input is [44, 53] the target: 56\n",
            "when input is [44, 53, 56] the target: 1\n",
            "when input is [44, 53, 56, 1] the target: 58\n",
            "when input is [44, 53, 56, 1, 58] the target: 46\n",
            "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
            "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
            "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52] the target: 58\n",
            "when input is [52, 58] the target: 1\n",
            "when input is [52, 58, 1] the target: 58\n",
            "when input is [52, 58, 1, 58] the target: 46\n",
            "when input is [52, 58, 1, 58, 46] the target: 39\n",
            "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
            "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
            "when input is [25] the target: 17\n",
            "when input is [25, 17] the target: 27\n",
            "when input is [25, 17, 27] the target: 10\n",
            "when input is [25, 17, 27, 10] the target: 0\n",
            "when input is [25, 17, 27, 10, 0] the target: 21\n",
            "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
            "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
            "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BigramLanguageModel"
      ],
      "metadata": {
        "id": "PtBliI3ShNNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        ##-- each token directly read oof the logits for the next token from a lookip table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        ##-- idx and targets are both (B, T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx) # (B, T, C) #-- (4, 8, 65), (batch_size, block_size, vocab_size)\n",
        "        # print(logits.shape) # (4, 8, 65)\n",
        "        # print(targets.shape) # (4, 8)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            ##-- из батча размером 4 предложения переводим в одну строку (то есть четыре предложения в одно)\n",
        "            logits = logits.view(B*T, C) ## (32, 65)\n",
        "            ##-- второй вариант, таргеты в таком случае тоже не менять\n",
        "            # logits = torch.permute(logits, (0, 2, 1))\n",
        "            targets = targets.view(B*T) ## (32)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens: int=100):\n",
        "        ##-- idx is the (B, T) array of the indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            ##-- get the predictions\n",
        "            logits, _ = self(idx)\n",
        "            ##-- focus only on the last time step (последнюю букву)\n",
        "            # print(f\"logits_before ={logits}, {logits.shape}\")\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # print(f\"logits_after ={logits}, {logits.shape}\")\n",
        "            ##-- softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # print(probs)\n",
        "            ##-- sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # print(idx_next)\n",
        "            ##-- append sampled idx to the running sample\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "\n",
        "# idx = torch.zeros((2, 1), dtype=torch.long)\n",
        "# print(idx)\n",
        "# m_gen = m.generate(idx, 100)\n",
        "# print(m_gen)\n",
        "# print(decode(m_gen[0].tolist()))\n",
        "# print(decode(m_gen))"
      ],
      "metadata": {
        "id": "ClxpK9PbnaAz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd86cb9-67f5-49e8-82af-3c54382c1269"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8786, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## optimizer"
      ],
      "metadata": {
        "id": "RDihrsjesoea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##-- pytorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "kh5zQz0kh9vL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(1000):\n",
        "    ##-- sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "    ##-- evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl-yUsOTsxXO",
        "outputId": "86484f35-09f8-4dc3-d91d-065a078bcbc2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.806382894515991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = torch.zeros((2, 1), dtype=torch.long)\n",
        "m_gen = m.generate(idx, 300)\n",
        "# print(m_gen)\n",
        "print(decode(m_gen[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzamqorptLK4",
        "outputId": "d45c259b-1d9f-4331-df01-21f4f103c02e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SK$G?wks;d F!WhP,SlRxjXy srTrjRjJMNAYdYlviOnQ!zEXXg;Sissw\n",
            "AkgjXEr&y,jKusuDHkzhSBibJUFlTCATErgCOQoCM$-wowaythjKby:CHpxQcma-b&yUzoaHo-IfqZIotiGjKApA?$gYn&QW fuky-MsycxqSl,\n",
            "Sv?q$sq,pyh rnQxyk\n",
            "SmJKHASxf?,susERn3d fmZMpoC-EZ-IVwF-pZMF.?oI'XjJXEr&!\n",
            "SZa faor$VqolmfBjUVRyoFo?helxjgmJHof bpT di;vW:CVJ?nQbEe,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title bigram.py\n",
        "bigram_script = \\\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "##-- hyperparameters\n",
        "batch_size = 32 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
        "block_size = 8 ##-- максимальная длина предложения (в нашем случае, количество символов)\n",
        "max_iters = 3000\n",
        "eval_interval = 300\n",
        "learning_rate = 1e-2\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "##------------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# here all the unique character that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "##-- create mapping from characters to integers\n",
        "stoi = { ch: i for i, ch in enumerate(chars) }\n",
        "atoi = { i: ch for i, ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([atoi[i] for i in l])\n",
        "\n",
        "##-- Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "##-- data loading\n",
        "def get_batch(split: str='train'):\n",
        "    '''\n",
        "    generate a small batch of data of inputs x and targets y\n",
        "\n",
        "    split: str: train or test\n",
        "    '''\n",
        "    data = train_data if split=='train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size, )) ##-- random idx\n",
        "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return (x, y)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "##-- super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        ##-- each token directly read oof the logits for the next token from a lookip table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        ##-- idx and targets are both (B, T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx) # (B, T, C) #-- (4, 8, 65), (batch_size, block_size, vocab_size)\n",
        "        # print(logits.shape) # (4, 8, 65)\n",
        "        # print(targets.shape) # (4, 8)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            ##-- из батча размером 4 предложения переводим в одну строку (то есть четыре предложения в одно)\n",
        "            logits = logits.view(B*T, C)\n",
        "            ##-- второй вариант, таргеты в таком случае тоже не менять\n",
        "            # logits = torch.permute(logits, (0, 2, 1))\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens: int=100):\n",
        "        ##-- idx is the (B, T) array of the indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            ##-- get the predictions\n",
        "            logits, _ = self(idx)\n",
        "            ##-- focus only on the last time step (последнюю букву)\n",
        "            # print(f\"logits_before ={logits}, {logits.shape}\")\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # print(f\"logits_after ={logits}, {logits.shape}\")\n",
        "            ##-- softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # print(probs)\n",
        "            ##-- sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # print(idx_next)\n",
        "            ##-- append sampled idx to the running sample\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel(vocab_size)\n",
        "m = model.to(device)\n",
        "\n",
        "##-- pytorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "\n",
        "##-- fit\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    ##-- sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    ##-- evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "##-- generate the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lCQ6uew9tjCo",
        "cellView": "form"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILENAME = 'bigram.py'\n",
        "save(bigram_script, FILENAME)"
      ],
      "metadata": {
        "id": "Hwv2UAlX0azD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b30313c-ac7e-41b8-94c1-8e343b8fb72b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved file at: /content/bigram.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "! python bigram.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxy3k3elS8Z5",
        "outputId": "39934600-27dd-476a-d907-36e22408d1d2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.7305, val loss 4.7241\n",
            "step 300: train loss 4.3818, val loss 4.3896\n",
            "step 600: train loss 4.0801, val loss 4.0784\n",
            "step 900: train loss 3.8066, val loss 3.8117\n",
            "step 1200: train loss 3.5844, val loss 3.5850\n",
            "step 1500: train loss 3.3757, val loss 3.3829\n",
            "step 1800: train loss 3.2182, val loss 3.2218\n",
            "step 2100: train loss 3.0817, val loss 3.0810\n",
            "step 2400: train loss 2.9663, val loss 2.9739\n",
            "step 2700: train loss 2.8809, val loss 2.8800\n",
            "\n",
            "\n",
            "\n",
            "CExfikRO:\n",
            "wcowi,STAOLOL, btK\n",
            "\n",
            "HAPTombobeAUGe.\n",
            "SGJO-33SM:C?YIUauss:LVXEthafNusqhathe.t?ar dXlaSpates wicrd RWI,\n",
            "DERacomzoroup\n",
            "Yow&$FMOUf isth bHEv!$Whedillxcaeg ireeYERngmin latiHNGAdrov ts, anenWk p.\n",
            "GRWilyWjbo!\n",
            "el.lind me u.\n",
            "-huD3SPy wiry:CUEOKMORT'X3Qw y. w'sBHUSInormopeYelgCIEJMk:\n",
            "Gll, d motSPkllo W-woo whrVCeiib3s wor m dE$HZAETENGShireAs p-LK3:Cl-xTre\n",
            "\n",
            "ALkOMmnterupt f s z; iris!\n",
            "m:CENGjey aleUE$ERUNMadPrD?d KISo myaHKINLIk!\n",
            "Ktiyb&y,:\n",
            "SadaplWPT:VE:zLUYBinin cNuk?ayeaney Iry tsmI&fy VEc!3My\n",
            "CPU times: user 107 ms, sys: 18.1 ms, total: 125 ms\n",
            "Wall time: 16.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self-attention\n",
        "\n",
        "Мы хотим, чтобы 5 токен узнал о 4-ем, третьем, втором, первом и нулевом токенах. Но не знал о шестом и так далее. Потому что мы не заглядываем в будущее\n",
        "\n",
        "Какой самый простой способ дать пятому токену информацию о предыдущих четырех?\n",
        "\n",
        "Усреднить предыдущие четыре (и наш пятый) - это и будет информация о нас и предыдущих токенах (истории).\n",
        "\n",
        "P.S. Усреднение - очень простой и слабый способ передачи информации, так как теряется очень много информации, но сейчас для практики - норм\n",
        "\n",
        "----\n",
        "Можно использовать взвешенную агрегацию предыдущих элементов, используя матричное перемножение"
      ],
      "metadata": {
        "id": "bmE5iKodsT4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "\n",
        "B, T, C = (4, 8, 2)\n",
        "x = torch.randn((B, T, C))\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyh22EmMuEq1",
        "outputId": "a312199b-efb5-44aa-8e82-4f66bddc2e62"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loop"
      ],
      "metadata": {
        "id": "cYHovGSm5txc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##-- version 1: use loop\n",
        "# we want x[b, t] = mean_{i<=t} x[b, i]\n",
        "xbow = torch.zeros((B, T, C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b, :t+1] # (t, C)\n",
        "        xbow[b, t] = torch.mean(xprev, dim=0)"
      ],
      "metadata": {
        "id": "4b97GT-nvFvO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Txa_9WPkyRaL",
        "outputId": "0e640953-43bc-4cd5-d21d-e4013bbbdbee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.3596, -0.9152],\n",
              "         [ 0.6258,  0.0255],\n",
              "         [ 0.9545,  0.0643],\n",
              "         [ 0.3612,  1.1679],\n",
              "         [-1.3499, -0.5102],\n",
              "         [ 0.2360, -0.2398],\n",
              "         [-0.9211,  1.5433]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.2858,  0.9651],\n",
              "         [-2.0371,  0.4931],\n",
              "         [ 1.4870,  0.5910],\n",
              "         [ 0.1260, -1.5627],\n",
              "         [-1.1601, -0.3348],\n",
              "         [ 0.4478, -0.8016],\n",
              "         [ 1.5236,  2.5086]],\n",
              "\n",
              "        [[-0.6631, -0.2513],\n",
              "         [ 1.0101,  0.1215],\n",
              "         [ 0.1584,  1.1340],\n",
              "         [-1.1539, -0.2984],\n",
              "         [-0.5075, -0.9239],\n",
              "         [ 0.5467, -1.4948],\n",
              "         [-1.2057,  0.5718],\n",
              "         [-0.5974, -0.6937]],\n",
              "\n",
              "        [[ 1.6455, -0.8030],\n",
              "         [ 1.3514, -0.2759],\n",
              "         [-1.5108,  2.1048],\n",
              "         [ 2.7630, -1.7465],\n",
              "         [ 1.4516, -1.5103],\n",
              "         [ 0.8212, -0.2115],\n",
              "         [ 0.7789,  1.5333],\n",
              "         [ 1.6097, -0.4032]]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPfUILyGx521",
        "outputId": "c0c5a62b-2fa2-41a5-bb41-f84593e47027"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]],\n",
              "\n",
              "        [[-0.6631, -0.2513],\n",
              "         [ 0.1735, -0.0649],\n",
              "         [ 0.1685,  0.3348],\n",
              "         [-0.1621,  0.1765],\n",
              "         [-0.2312, -0.0436],\n",
              "         [-0.1015, -0.2855],\n",
              "         [-0.2593, -0.1630],\n",
              "         [-0.3015, -0.2293]],\n",
              "\n",
              "        [[ 1.6455, -0.8030],\n",
              "         [ 1.4985, -0.5395],\n",
              "         [ 0.4954,  0.3420],\n",
              "         [ 1.0623, -0.1802],\n",
              "         [ 1.1401, -0.4462],\n",
              "         [ 1.0870, -0.4071],\n",
              "         [ 1.0430, -0.1299],\n",
              "         [ 1.1138, -0.1641]]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si5i5-uoxumV",
        "outputId": "1f6f49de-999e-46c0-9780-743825544c95"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.3596, -0.9152],\n",
              "         [ 0.6258,  0.0255],\n",
              "         [ 0.9545,  0.0643],\n",
              "         [ 0.3612,  1.1679],\n",
              "         [-1.3499, -0.5102],\n",
              "         [ 0.2360, -0.2398],\n",
              "         [-0.9211,  1.5433]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.2858,  0.9651],\n",
              "         [-2.0371,  0.4931],\n",
              "         [ 1.4870,  0.5910],\n",
              "         [ 0.1260, -1.5627],\n",
              "         [-1.1601, -0.3348],\n",
              "         [ 0.4478, -0.8016],\n",
              "         [ 1.5236,  2.5086]],\n",
              "\n",
              "        [[-0.6631, -0.2513],\n",
              "         [ 1.0101,  0.1215],\n",
              "         [ 0.1584,  1.1340],\n",
              "         [-1.1539, -0.2984],\n",
              "         [-0.5075, -0.9239],\n",
              "         [ 0.5467, -1.4948],\n",
              "         [-1.2057,  0.5718],\n",
              "         [-0.5974, -0.6937]],\n",
              "\n",
              "        [[ 1.6455, -0.8030],\n",
              "         [ 1.3514, -0.2759],\n",
              "         [-1.5108,  2.1048],\n",
              "         [ 2.7630, -1.7465],\n",
              "         [ 1.4516, -1.5103],\n",
              "         [ 0.8212, -0.2115],\n",
              "         [ 0.7789,  1.5333],\n",
              "         [ 1.6097, -0.4032]]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.ones(3, 3)\n",
        "b = torch.randint(0, 10, (3, 2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq3Xskr_xvQ9",
        "outputId": "eb567a70-89b8-4a53-8bc3-22d74fd460bd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[14., 16.],\n",
            "        [14., 16.],\n",
            "        [14., 16.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##-- трюк - как проссумировать строки матричным перемножением\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "b = torch.randint(0, 10, (3, 2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Wr06SXPzaoB",
        "outputId": "19f38c2a-d07e-4bb8-8f2d-354a8e3b237b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1., 0., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 1.]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[ 2.,  7.],\n",
            "        [ 8., 11.],\n",
            "        [14., 16.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##-- трюк - как получить среднее матричным перемножением\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "sum_ = torch.sum(a, 1, keepdim=True)\n",
        "print(f\"sum_={sum_}\")\n",
        "a = a / sum_\n",
        "b = torch.randint(0, 10, (3, 2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqAZDRha1zRh",
        "outputId": "d638a8d7-d5a1-4ce6-a584-9499f3e5ebbe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sum_=tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix"
      ],
      "metadata": {
        "id": "HfquU4AQ5wVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##-- version 2: use matrix\n",
        "wei = torch.tril(torch.ones((T, T)))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)"
      ],
      "metadata": {
        "id": "NJ_TbvVl0OAo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktQ5-QTC0Vgz",
        "outputId": "2414f0ba-93df-4e82-cfa1-85c20f6f8c3a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd-9ruBu0qLc",
        "outputId": "388955cf-9c61-4914-d0d4-1c6b4b07c2bb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]],\n",
              "\n",
              "        [[-0.6631, -0.2513],\n",
              "         [ 0.1735, -0.0649],\n",
              "         [ 0.1685,  0.3348],\n",
              "         [-0.1621,  0.1765],\n",
              "         [-0.2312, -0.0436],\n",
              "         [-0.1015, -0.2855],\n",
              "         [-0.2593, -0.1630],\n",
              "         [-0.3015, -0.2293]],\n",
              "\n",
              "        [[ 1.6455, -0.8030],\n",
              "         [ 1.4985, -0.5395],\n",
              "         [ 0.4954,  0.3420],\n",
              "         [ 1.0623, -0.1802],\n",
              "         [ 1.1401, -0.4462],\n",
              "         [ 1.0870, -0.4071],\n",
              "         [ 1.0430, -0.1299],\n",
              "         [ 1.1138, -0.1641]]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##-- матричным перемножением получаем такой же результат\n",
        "torch.allclose(xbow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3lugq2q2ttT",
        "outputId": "0660ab4f-b9d1-41f4-eeb4-15336563050a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use softmax"
      ],
      "metadata": {
        "id": "_RJ5aqrA0zLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##-- version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T)) ##-- сколько элементов агрегируется\n",
        "print(f\"tril={tril}\")\n",
        "print('----')\n",
        "\n",
        "wei = torch.zeros((T, T))\n",
        "print(f\"wei={wei}\")\n",
        "print('----')\n",
        "\n",
        "wei = wei.masked_fill(tril==0, float('-inf'))\n",
        "print(f\"wei={wei}\")\n",
        "print('----')\n",
        "\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "print(f\"wei={wei}\")\n",
        "print('----')\n",
        "\n",
        "xbow3 = wei @ x\n",
        "print(f\"xbow3={xbow3}\")\n",
        "print('----')\n",
        "torch.allclose(xbow, xbow3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsUB-d3w0yqx",
        "outputId": "ab5ce6ea-7ffa-4eac-851b-bdce2d3816f4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tril=tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "----\n",
            "wei=tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "----\n",
            "wei=tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "----\n",
            "wei=tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
            "----\n",
            "xbow3=tensor([[[ 0.1808, -0.0700],\n",
            "         [-0.0894, -0.4926],\n",
            "         [ 0.1490, -0.3199],\n",
            "         [ 0.3504, -0.2238],\n",
            "         [ 0.3525,  0.0545],\n",
            "         [ 0.0688, -0.0396],\n",
            "         [ 0.0927, -0.0682],\n",
            "         [-0.0341,  0.1332]],\n",
            "\n",
            "        [[ 1.3488, -0.1396],\n",
            "         [ 0.8173,  0.4127],\n",
            "         [-0.1342,  0.4395],\n",
            "         [ 0.2711,  0.4774],\n",
            "         [ 0.2421,  0.0694],\n",
            "         [ 0.0084,  0.0020],\n",
            "         [ 0.0712, -0.1128],\n",
            "         [ 0.2527,  0.2149]],\n",
            "\n",
            "        [[-0.6631, -0.2513],\n",
            "         [ 0.1735, -0.0649],\n",
            "         [ 0.1685,  0.3348],\n",
            "         [-0.1621,  0.1765],\n",
            "         [-0.2312, -0.0436],\n",
            "         [-0.1015, -0.2855],\n",
            "         [-0.2593, -0.1630],\n",
            "         [-0.3015, -0.2293]],\n",
            "\n",
            "        [[ 1.6455, -0.8030],\n",
            "         [ 1.4985, -0.5395],\n",
            "         [ 0.4954,  0.3420],\n",
            "         [ 1.0623, -0.1802],\n",
            "         [ 1.1401, -0.4462],\n",
            "         [ 1.0870, -0.4071],\n",
            "         [ 1.0430, -0.1299],\n",
            "         [ 1.1138, -0.1641]]])\n",
            "----\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title bigram_v2.py\n",
        "bigram_v2 = \\\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "##-- hyperparameters\n",
        "batch_size = 4 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
        "block_size = 8 ##-- максимальная длина предложения (в нашем случае, количество символов)\n",
        "max_iters = 300\n",
        "eval_interval = 300\n",
        "learning_rate = 1e-2\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 32 ##-- размер эмбединга\n",
        "##------------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# here all the unique character that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "##-- create mapping from characters to integers\n",
        "stoi = { ch: i for i, ch in enumerate(chars) }\n",
        "atoi = { i: ch for i, ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([atoi[i] for i in l])\n",
        "\n",
        "##-- Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "##-- data loading\n",
        "def get_batch(split: str='train'):\n",
        "    '''\n",
        "    generate a small batch of data of inputs x and targets y\n",
        "\n",
        "    split: str: train or test\n",
        "    '''\n",
        "    data = train_data if split=='train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size, )) ##-- random idx\n",
        "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return (x, y)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "##-- super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ##-- each token directly read oof the logits for the next token from a lookip table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) ##-- берем эмбединг токена (кодируем токен)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd) ##-- кодируем позицию токена\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size) ##-- linear_model head\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        ##-- idx and targets are both (B, T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B, T, C) #-- (4, 8, 32), (batch_size, block_size, emb_size)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C) (8, 32) ##-- кодируем позицию токена\n",
        "        x = tok_emb + pos_emb ##-- (B, T, C) эмбединг токена и его позиции\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size) #-- (4, 8, 65), (batch_size, block_size, vocab_size)\n",
        "        # print(logits.shape) # (4, 8, 65)\n",
        "        # print(targets.shape) # (4, 8)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            ##-- из батча размером 4 предложения переводим в одну строку (то есть четыре предложения в одно)\n",
        "            logits = logits.view(B*T, C)\n",
        "            ##-- второй вариант, таргеты в таком случае тоже не менять\n",
        "            # logits = torch.permute(logits, (0, 2, 1))\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens: int=100):\n",
        "        ##-- idx is the (B, T) array of the indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            ##-- get the predictions\n",
        "            logits, _ = self(idx)\n",
        "            ##-- focus only on the last time step (последнюю букву)\n",
        "            print(f\"logits_before ={logits}, {logits.shape}\")\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            print(f\"logits_after ={logits}, {logits.shape}\")\n",
        "            ##-- softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            print(probs)\n",
        "            ##-- sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            print(idx_next)\n",
        "            ##-- append sampled idx to the running sample\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "\n",
        "##-- pytorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "\n",
        "##-- fit\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    ##-- sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    ##-- evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "##-- generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=10)[0].tolist()))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SES94jYQ84dd",
        "cellView": "form"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILENAME = 'bigram_v2.py'\n",
        "save(bigram_v2, FILENAME)"
      ],
      "metadata": {
        "id": "QfyNE5n71wJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e90c128-3a02-44e1-bbd6-1b30e2bab222"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved file at: /content/bigram_v2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! diff bigram.py bigram_v2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HphXyl9pSWvT",
        "outputId": "d8f68a30-be89-4673-fe1c-689b50f69254"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1a2\n",
            "> \n",
            "7c8\n",
            "< batch_size = 32 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
            "---\n",
            "> batch_size = 4 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
            "9c10\n",
            "< max_iters = 3000\n",
            "---\n",
            "> max_iters = 300\n",
            "13a15\n",
            "> n_embd = 32 ##-- размер эмбединга\n",
            "68c70\n",
            "<     def __init__(self, vocab_size):\n",
            "---\n",
            ">     def __init__(self):\n",
            "71c73,75\n",
            "<         self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
            "---\n",
            ">         self.token_embedding_table = nn.Embedding(vocab_size, n_embd) ##-- берем эмбединг токена (кодируем токен)\n",
            ">         self.position_embedding_table = nn.Embedding(block_size, n_embd) ##-- кодируем позицию токена\n",
            ">         self.lm_head = nn.Linear(n_embd, vocab_size) ##-- linear_model head\n",
            "73a78,79\n",
            ">         B, T = idx.shape\n",
            "> \n",
            "75c81,84\n",
            "<         logits = self.token_embedding_table(idx) # (B, T, C) #-- (4, 8, 65), (batch_size, block_size, vocab_size)\n",
            "---\n",
            ">         tok_emb = self.token_embedding_table(idx) # (B, T, C) #-- (4, 8, 32), (batch_size, block_size, emb_size)\n",
            ">         pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C) (8, 32) ##-- кодируем позицию токена\n",
            ">         x = tok_emb + pos_emb ##-- (B, T, C) эмбединг токена и его позиции\n",
            ">         logits = self.lm_head(x) # (B, T, vocab_size) #-- (4, 8, 65), (batch_size, block_size, vocab_size)\n",
            "97c106\n",
            "<             # print(f\"logits_before ={logits}, {logits.shape}\")\n",
            "---\n",
            ">             print(f\"logits_before ={logits}, {logits.shape}\")\n",
            "99c108\n",
            "<             # print(f\"logits_after ={logits}, {logits.shape}\")\n",
            "---\n",
            ">             print(f\"logits_after ={logits}, {logits.shape}\")\n",
            "102c111\n",
            "<             # print(probs)\n",
            "---\n",
            ">             print(probs)\n",
            "105c114\n",
            "<             # print(idx_next)\n",
            "---\n",
            ">             print(idx_next)\n",
            "110c119\n",
            "< model = BigramLanguageModel(vocab_size)\n",
            "---\n",
            "> model = BigramLanguageModel()\n",
            "127c136\n",
            "<     logits, loss = m(xb, yb)\n",
            "---\n",
            ">     logits, loss = model(xb, yb)\n",
            "132c141\n",
            "< ##-- generate the model\n",
            "---\n",
            "> ##-- generate from the model\n",
            "134c143,144\n",
            "< print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
            "---\n",
            "> print(decode(m.generate(context, max_new_tokens=10)[0].tolist()))\n",
            "> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "! python bigram_v2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxfyV8d8S5fe",
        "outputId": "62eeb33d-8021-46a8-ae0a-80d3ec69e61a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.4701, val loss 4.4930\n",
            "logits_before =tensor([[[ 0.1875,  0.2098, -1.2989, -0.7939, -0.6377, -0.5834, -0.1427,\n",
            "          -1.3647, -0.8279, -0.9151, -0.7947, -1.2249, -0.4032,  0.4988,\n",
            "          -0.2799,  0.0588,  0.0020, -0.7513, -0.9078, -0.9270,  0.2285,\n",
            "          -0.6461, -0.6058, -0.5217, -0.5360,  0.4208, -0.5117, -0.0905,\n",
            "          -0.2599, -0.5530,  0.3508,  1.0032,  0.1444, -0.4868, -0.4084,\n",
            "          -0.1927, -1.1498, -1.0945, -0.6877,  0.3868, -0.0950,  0.1140,\n",
            "          -0.3839, -0.2191,  0.1055,  0.3010, -0.7910, -0.5693, -0.4552,\n",
            "          -0.1785, -0.3584,  0.4609,  0.9867, -0.2026, -0.3343, -0.4283,\n",
            "           0.8460,  0.1427,  0.0605, -1.2164, -0.0200, -0.0623, -0.9823,\n",
            "          -0.1947, -0.5709]]], device='cuda:0', grad_fn=<ViewBackward0>), torch.Size([1, 1, 65])\n",
            "logits_after =tensor([[ 0.1875,  0.2098, -1.2989, -0.7939, -0.6377, -0.5834, -0.1427, -1.3647,\n",
            "         -0.8279, -0.9151, -0.7947, -1.2249, -0.4032,  0.4988, -0.2799,  0.0588,\n",
            "          0.0020, -0.7513, -0.9078, -0.9270,  0.2285, -0.6461, -0.6058, -0.5217,\n",
            "         -0.5360,  0.4208, -0.5117, -0.0905, -0.2599, -0.5530,  0.3508,  1.0032,\n",
            "          0.1444, -0.4868, -0.4084, -0.1927, -1.1498, -1.0945, -0.6877,  0.3868,\n",
            "         -0.0950,  0.1140, -0.3839, -0.2191,  0.1055,  0.3010, -0.7910, -0.5693,\n",
            "         -0.4552, -0.1785, -0.3584,  0.4609,  0.9867, -0.2026, -0.3343, -0.4283,\n",
            "          0.8460,  0.1427,  0.0605, -1.2164, -0.0200, -0.0623, -0.9823, -0.1947,\n",
            "         -0.5709]], device='cuda:0', grad_fn=<SliceBackward0>), torch.Size([1, 65])\n",
            "tensor([[0.0218, 0.0223, 0.0049, 0.0082, 0.0095, 0.0101, 0.0156, 0.0046, 0.0079,\n",
            "         0.0072, 0.0081, 0.0053, 0.0121, 0.0297, 0.0136, 0.0191, 0.0181, 0.0085,\n",
            "         0.0073, 0.0071, 0.0227, 0.0095, 0.0098, 0.0107, 0.0106, 0.0275, 0.0108,\n",
            "         0.0165, 0.0139, 0.0104, 0.0256, 0.0492, 0.0208, 0.0111, 0.0120, 0.0149,\n",
            "         0.0057, 0.0060, 0.0091, 0.0266, 0.0164, 0.0202, 0.0123, 0.0145, 0.0201,\n",
            "         0.0244, 0.0082, 0.0102, 0.0114, 0.0151, 0.0126, 0.0286, 0.0484, 0.0147,\n",
            "         0.0129, 0.0118, 0.0420, 0.0208, 0.0192, 0.0053, 0.0177, 0.0170, 0.0068,\n",
            "         0.0149, 0.0102]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[12]], device='cuda:0')\n",
            "logits_before =tensor([[[ 0.1875,  0.2098, -1.2989, -0.7939, -0.6377, -0.5834, -0.1427,\n",
            "          -1.3647, -0.8279, -0.9151, -0.7947, -1.2249, -0.4032,  0.4988,\n",
            "          -0.2799,  0.0588,  0.0020, -0.7513, -0.9078, -0.9270,  0.2285,\n",
            "          -0.6461, -0.6058, -0.5217, -0.5360,  0.4208, -0.5117, -0.0905,\n",
            "          -0.2599, -0.5530,  0.3508,  1.0032,  0.1444, -0.4868, -0.4084,\n",
            "          -0.1927, -1.1498, -1.0945, -0.6877,  0.3868, -0.0950,  0.1140,\n",
            "          -0.3839, -0.2191,  0.1055,  0.3010, -0.7910, -0.5693, -0.4552,\n",
            "          -0.1785, -0.3584,  0.4609,  0.9867, -0.2026, -0.3343, -0.4283,\n",
            "           0.8460,  0.1427,  0.0605, -1.2164, -0.0200, -0.0623, -0.9823,\n",
            "          -0.1947, -0.5709],\n",
            "         [ 1.1642,  1.6613, -0.6792, -0.3746, -1.6222, -0.2530, -0.6532,\n",
            "           0.0029,  0.0056, -1.3995, -0.3058, -0.8418, -0.2677, -0.4955,\n",
            "          -1.4925, -1.3951, -0.4845, -1.1631, -0.8578, -1.5033, -0.1409,\n",
            "           0.1740, -0.9265, -0.2717,  0.1885, -0.6410, -0.2191, -0.0705,\n",
            "          -1.3935, -1.9125, -0.5005,  0.2208, -0.3521,  0.2450, -0.7511,\n",
            "          -0.7697, -0.8034, -0.3788, -1.7138,  0.6202, -0.3666,  0.1549,\n",
            "          -0.6182,  0.4079,  0.1703, -1.0020,  0.5623,  0.2392, -0.6669,\n",
            "          -0.7443,  0.2362,  0.7012,  0.7165,  0.1491, -0.5700, -0.8101,\n",
            "           0.9183,  0.4554,  0.2045, -0.8355, -0.9480,  0.4812, -1.0458,\n",
            "           0.3671, -1.8081]]], device='cuda:0', grad_fn=<ViewBackward0>), torch.Size([1, 2, 65])\n",
            "logits_after =tensor([[ 1.1642,  1.6613, -0.6792, -0.3746, -1.6222, -0.2530, -0.6532,  0.0029,\n",
            "          0.0056, -1.3995, -0.3058, -0.8418, -0.2677, -0.4955, -1.4925, -1.3951,\n",
            "         -0.4845, -1.1631, -0.8578, -1.5033, -0.1409,  0.1740, -0.9265, -0.2717,\n",
            "          0.1885, -0.6410, -0.2191, -0.0705, -1.3935, -1.9125, -0.5005,  0.2208,\n",
            "         -0.3521,  0.2450, -0.7511, -0.7697, -0.8034, -0.3788, -1.7138,  0.6202,\n",
            "         -0.3666,  0.1549, -0.6182,  0.4079,  0.1703, -1.0020,  0.5623,  0.2392,\n",
            "         -0.6669, -0.7443,  0.2362,  0.7012,  0.7165,  0.1491, -0.5700, -0.8101,\n",
            "          0.9183,  0.4554,  0.2045, -0.8355, -0.9480,  0.4812, -1.0458,  0.3671,\n",
            "         -1.8081]], device='cuda:0', grad_fn=<SliceBackward0>), torch.Size([1, 65])\n",
            "tensor([[0.0537, 0.0882, 0.0085, 0.0115, 0.0033, 0.0130, 0.0087, 0.0168, 0.0168,\n",
            "         0.0041, 0.0123, 0.0072, 0.0128, 0.0102, 0.0038, 0.0042, 0.0103, 0.0052,\n",
            "         0.0071, 0.0037, 0.0145, 0.0199, 0.0066, 0.0128, 0.0202, 0.0088, 0.0135,\n",
            "         0.0156, 0.0042, 0.0025, 0.0102, 0.0209, 0.0118, 0.0214, 0.0079, 0.0078,\n",
            "         0.0075, 0.0115, 0.0030, 0.0311, 0.0116, 0.0196, 0.0090, 0.0252, 0.0199,\n",
            "         0.0061, 0.0294, 0.0213, 0.0086, 0.0080, 0.0212, 0.0338, 0.0343, 0.0194,\n",
            "         0.0095, 0.0075, 0.0420, 0.0264, 0.0206, 0.0073, 0.0065, 0.0271, 0.0059,\n",
            "         0.0242, 0.0027]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0]], device='cuda:0')\n",
            "logits_before =tensor([[[ 0.1875,  0.2098, -1.2989, -0.7939, -0.6377, -0.5834, -0.1427,\n",
            "          -1.3647, -0.8279, -0.9151, -0.7947, -1.2249, -0.4032,  0.4988,\n",
            "          -0.2799,  0.0588,  0.0020, -0.7513, -0.9078, -0.9270,  0.2285,\n",
            "          -0.6461, -0.6058, -0.5217, -0.5360,  0.4208, -0.5117, -0.0905,\n",
            "          -0.2599, -0.5530,  0.3508,  1.0032,  0.1444, -0.4868, -0.4084,\n",
            "          -0.1927, -1.1498, -1.0945, -0.6877,  0.3868, -0.0950,  0.1140,\n",
            "          -0.3839, -0.2191,  0.1055,  0.3010, -0.7910, -0.5693, -0.4552,\n",
            "          -0.1785, -0.3584,  0.4609,  0.9867, -0.2026, -0.3343, -0.4283,\n",
            "           0.8460,  0.1427,  0.0605, -1.2164, -0.0200, -0.0623, -0.9823,\n",
            "          -0.1947, -0.5709],\n",
            "         [ 1.1642,  1.6613, -0.6792, -0.3746, -1.6222, -0.2530, -0.6532,\n",
            "           0.0029,  0.0056, -1.3995, -0.3058, -0.8418, -0.2677, -0.4955,\n",
            "          -1.4925, -1.3951, -0.4845, -1.1631, -0.8578, -1.5033, -0.1409,\n",
            "           0.1740, -0.9265, -0.2717,  0.1885, -0.6410, -0.2191, -0.0705,\n",
            "          -1.3935, -1.9125, -0.5005,  0.2208, -0.3521,  0.2450, -0.7511,\n",
            "          -0.7697, -0.8034, -0.3788, -1.7138,  0.6202, -0.3666,  0.1549,\n",
            "          -0.6182,  0.4079,  0.1703, -1.0020,  0.5623,  0.2392, -0.6669,\n",
            "          -0.7443,  0.2362,  0.7012,  0.7165,  0.1491, -0.5700, -0.8101,\n",
            "           0.9183,  0.4554,  0.2045, -0.8355, -0.9480,  0.4812, -1.0458,\n",
            "           0.3671, -1.8081],\n",
            "         [ 0.7723,  0.9672, -1.1015, -1.2027, -0.6764, -0.7538,  0.4044,\n",
            "          -1.0906, -0.4620, -1.1744, -1.5801, -1.0385, -0.1700,  0.9591,\n",
            "          -0.1076,  0.4725, -0.0150, -0.1416, -0.4993, -0.7703,  0.7040,\n",
            "          -0.6650, -0.4041,  0.0511,  0.3609,  0.6502, -0.1975, -0.0707,\n",
            "          -0.1796, -0.6059,  0.0902,  0.0327,  0.9072, -0.7568,  0.1818,\n",
            "          -0.1218, -1.1516, -0.7634, -0.8937,  0.9985, -0.1201, -0.4954,\n",
            "          -0.4542,  0.4308,  0.2143,  0.2643, -0.0224, -0.8733, -1.1162,\n",
            "          -0.7784, -0.4036, -0.2392,  0.1423, -0.1465,  0.0393, -0.6774,\n",
            "           0.7787,  0.1172,  0.5995, -1.3653, -0.1401, -0.3886, -1.1252,\n",
            "           0.3776, -0.5828]]], device='cuda:0', grad_fn=<ViewBackward0>), torch.Size([1, 3, 65])\n",
            "logits_after =tensor([[ 0.7723,  0.9672, -1.1015, -1.2027, -0.6764, -0.7538,  0.4044, -1.0906,\n",
            "         -0.4620, -1.1744, -1.5801, -1.0385, -0.1700,  0.9591, -0.1076,  0.4725,\n",
            "         -0.0150, -0.1416, -0.4993, -0.7703,  0.7040, -0.6650, -0.4041,  0.0511,\n",
            "          0.3609,  0.6502, -0.1975, -0.0707, -0.1796, -0.6059,  0.0902,  0.0327,\n",
            "          0.9072, -0.7568,  0.1818, -0.1218, -1.1516, -0.7634, -0.8937,  0.9985,\n",
            "         -0.1201, -0.4954, -0.4542,  0.4308,  0.2143,  0.2643, -0.0224, -0.8733,\n",
            "         -1.1162, -0.7784, -0.4036, -0.2392,  0.1423, -0.1465,  0.0393, -0.6774,\n",
            "          0.7787,  0.1172,  0.5995, -1.3653, -0.1401, -0.3886, -1.1252,  0.3776,\n",
            "         -0.5828]], device='cuda:0', grad_fn=<SliceBackward0>), torch.Size([1, 65])\n",
            "tensor([[0.0343, 0.0417, 0.0053, 0.0048, 0.0081, 0.0075, 0.0237, 0.0053, 0.0100,\n",
            "         0.0049, 0.0033, 0.0056, 0.0134, 0.0414, 0.0142, 0.0254, 0.0156, 0.0138,\n",
            "         0.0096, 0.0073, 0.0320, 0.0081, 0.0106, 0.0167, 0.0227, 0.0304, 0.0130,\n",
            "         0.0148, 0.0132, 0.0086, 0.0173, 0.0164, 0.0393, 0.0074, 0.0190, 0.0140,\n",
            "         0.0050, 0.0074, 0.0065, 0.0430, 0.0141, 0.0097, 0.0101, 0.0244, 0.0196,\n",
            "         0.0206, 0.0155, 0.0066, 0.0052, 0.0073, 0.0106, 0.0125, 0.0183, 0.0137,\n",
            "         0.0165, 0.0080, 0.0345, 0.0178, 0.0289, 0.0040, 0.0138, 0.0107, 0.0051,\n",
            "         0.0231, 0.0088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[44]], device='cuda:0')\n",
            "logits_before =tensor([[[ 1.8752e-01,  2.0979e-01, -1.2989e+00, -7.9388e-01, -6.3770e-01,\n",
            "          -5.8339e-01, -1.4268e-01, -1.3647e+00, -8.2792e-01, -9.1511e-01,\n",
            "          -7.9475e-01, -1.2249e+00, -4.0322e-01,  4.9877e-01, -2.7988e-01,\n",
            "           5.8756e-02,  2.0424e-03, -7.5130e-01, -9.0779e-01, -9.2699e-01,\n",
            "           2.2848e-01, -6.4609e-01, -6.0584e-01, -5.2174e-01, -5.3596e-01,\n",
            "           4.2081e-01, -5.1171e-01, -9.0460e-02, -2.5988e-01, -5.5300e-01,\n",
            "           3.5079e-01,  1.0032e+00,  1.4442e-01, -4.8678e-01, -4.0837e-01,\n",
            "          -1.9268e-01, -1.1498e+00, -1.0945e+00, -6.8773e-01,  3.8678e-01,\n",
            "          -9.4970e-02,  1.1400e-01, -3.8394e-01, -2.1912e-01,  1.0550e-01,\n",
            "           3.0104e-01, -7.9097e-01, -5.6930e-01, -4.5517e-01, -1.7853e-01,\n",
            "          -3.5843e-01,  4.6095e-01,  9.8668e-01, -2.0263e-01, -3.3431e-01,\n",
            "          -4.2826e-01,  8.4598e-01,  1.4269e-01,  6.0546e-02, -1.2164e+00,\n",
            "          -2.0032e-02, -6.2261e-02, -9.8231e-01, -1.9472e-01, -5.7090e-01],\n",
            "         [ 1.1642e+00,  1.6613e+00, -6.7925e-01, -3.7455e-01, -1.6222e+00,\n",
            "          -2.5299e-01, -6.5324e-01,  2.9374e-03,  5.6250e-03, -1.3995e+00,\n",
            "          -3.0582e-01, -8.4179e-01, -2.6771e-01, -4.9547e-01, -1.4925e+00,\n",
            "          -1.3951e+00, -4.8448e-01, -1.1631e+00, -8.5781e-01, -1.5033e+00,\n",
            "          -1.4092e-01,  1.7398e-01, -9.2655e-01, -2.7173e-01,  1.8854e-01,\n",
            "          -6.4101e-01, -2.1906e-01, -7.0469e-02, -1.3935e+00, -1.9125e+00,\n",
            "          -5.0050e-01,  2.2084e-01, -3.5208e-01,  2.4499e-01, -7.5112e-01,\n",
            "          -7.6965e-01, -8.0344e-01, -3.7883e-01, -1.7138e+00,  6.2022e-01,\n",
            "          -3.6659e-01,  1.5488e-01, -6.1825e-01,  4.0788e-01,  1.7027e-01,\n",
            "          -1.0020e+00,  5.6231e-01,  2.3916e-01, -6.6693e-01, -7.4426e-01,\n",
            "           2.3622e-01,  7.0120e-01,  7.1650e-01,  1.4907e-01, -5.6999e-01,\n",
            "          -8.1014e-01,  9.1825e-01,  4.5538e-01,  2.0455e-01, -8.3555e-01,\n",
            "          -9.4799e-01,  4.8116e-01, -1.0458e+00,  3.6714e-01, -1.8081e+00],\n",
            "         [ 7.7229e-01,  9.6716e-01, -1.1015e+00, -1.2027e+00, -6.7637e-01,\n",
            "          -7.5378e-01,  4.0436e-01, -1.0906e+00, -4.6205e-01, -1.1744e+00,\n",
            "          -1.5801e+00, -1.0385e+00, -1.6995e-01,  9.5915e-01, -1.0762e-01,\n",
            "           4.7255e-01, -1.4991e-02, -1.4164e-01, -4.9926e-01, -7.7031e-01,\n",
            "           7.0395e-01, -6.6496e-01, -4.0410e-01,  5.1104e-02,  3.6092e-01,\n",
            "           6.5023e-01, -1.9751e-01, -7.0695e-02, -1.7957e-01, -6.0587e-01,\n",
            "           9.0232e-02,  3.2680e-02,  9.0719e-01, -7.5681e-01,  1.8180e-01,\n",
            "          -1.2175e-01, -1.1516e+00, -7.6338e-01, -8.9370e-01,  9.9849e-01,\n",
            "          -1.2010e-01, -4.9536e-01, -4.5423e-01,  4.3081e-01,  2.1429e-01,\n",
            "           2.6433e-01, -2.2432e-02, -8.7333e-01, -1.1162e+00, -7.7844e-01,\n",
            "          -4.0356e-01, -2.3925e-01,  1.4233e-01, -1.4650e-01,  3.9255e-02,\n",
            "          -6.7736e-01,  7.7873e-01,  1.1722e-01,  5.9948e-01, -1.3653e+00,\n",
            "          -1.4014e-01, -3.8860e-01, -1.1252e+00,  3.7759e-01, -5.8280e-01],\n",
            "         [ 5.4533e-01,  2.0446e+00, -8.4777e-01, -1.0492e+00, -1.2622e+00,\n",
            "          -5.9312e-01,  6.4782e-01,  9.0300e-02,  4.6148e-01, -1.3712e+00,\n",
            "           2.4966e-01, -1.4924e+00, -5.7184e-01, -5.0129e-01, -8.2124e-01,\n",
            "          -1.7031e+00, -6.8233e-01, -2.5186e-01, -1.0939e+00, -9.8248e-01,\n",
            "          -1.1883e+00, -2.1540e-01, -1.9727e+00, -1.2081e+00, -3.7759e-01,\n",
            "          -1.7058e+00, -5.9694e-01, -3.4047e-01, -9.7379e-01, -1.8960e+00,\n",
            "          -9.1055e-01, -8.0624e-01, -1.0026e+00, -1.3787e+00, -1.8169e+00,\n",
            "          -5.6109e-02, -1.5968e+00, -8.9530e-01, -2.2088e+00,  7.5361e-01,\n",
            "          -8.1806e-01, -4.0454e-01, -1.8056e-01,  1.3425e+00, -9.7675e-01,\n",
            "           2.5477e-01,  1.0357e+00,  3.9171e-01, -9.9557e-01,  1.1888e-01,\n",
            "           8.4718e-01, -1.6059e+00,  2.4068e-01,  7.5017e-01, -9.9189e-01,\n",
            "          -9.0575e-01,  3.7788e-01,  5.9699e-01,  2.3085e-02, -3.5115e-01,\n",
            "          -1.0802e+00, -1.5128e-01, -1.0956e+00,  4.9171e-01, -7.8917e-01]]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>), torch.Size([1, 4, 65])\n",
            "logits_after =tensor([[ 0.5453,  2.0446, -0.8478, -1.0492, -1.2622, -0.5931,  0.6478,  0.0903,\n",
            "          0.4615, -1.3712,  0.2497, -1.4924, -0.5718, -0.5013, -0.8212, -1.7031,\n",
            "         -0.6823, -0.2519, -1.0939, -0.9825, -1.1883, -0.2154, -1.9727, -1.2081,\n",
            "         -0.3776, -1.7058, -0.5969, -0.3405, -0.9738, -1.8960, -0.9106, -0.8062,\n",
            "         -1.0026, -1.3787, -1.8169, -0.0561, -1.5968, -0.8953, -2.2088,  0.7536,\n",
            "         -0.8181, -0.4045, -0.1806,  1.3425, -0.9768,  0.2548,  1.0357,  0.3917,\n",
            "         -0.9956,  0.1189,  0.8472, -1.6059,  0.2407,  0.7502, -0.9919, -0.9058,\n",
            "          0.3779,  0.5970,  0.0231, -0.3512, -1.0802, -0.1513, -1.0956,  0.4917,\n",
            "         -0.7892]], device='cuda:0', grad_fn=<SliceBackward0>), torch.Size([1, 65])\n",
            "tensor([[0.0291, 0.1301, 0.0072, 0.0059, 0.0048, 0.0093, 0.0322, 0.0184, 0.0267,\n",
            "         0.0043, 0.0216, 0.0038, 0.0095, 0.0102, 0.0074, 0.0031, 0.0085, 0.0131,\n",
            "         0.0056, 0.0063, 0.0051, 0.0136, 0.0023, 0.0050, 0.0115, 0.0031, 0.0093,\n",
            "         0.0120, 0.0064, 0.0025, 0.0068, 0.0075, 0.0062, 0.0042, 0.0027, 0.0159,\n",
            "         0.0034, 0.0069, 0.0018, 0.0358, 0.0074, 0.0112, 0.0141, 0.0645, 0.0063,\n",
            "         0.0217, 0.0474, 0.0249, 0.0062, 0.0190, 0.0393, 0.0034, 0.0214, 0.0357,\n",
            "         0.0062, 0.0068, 0.0246, 0.0306, 0.0172, 0.0119, 0.0057, 0.0145, 0.0056,\n",
            "         0.0275, 0.0076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[52]], device='cuda:0')\n",
            "logits_before =tensor([[[ 1.8752e-01,  2.0979e-01, -1.2989e+00, -7.9388e-01, -6.3770e-01,\n",
            "          -5.8339e-01, -1.4268e-01, -1.3647e+00, -8.2792e-01, -9.1511e-01,\n",
            "          -7.9475e-01, -1.2249e+00, -4.0322e-01,  4.9877e-01, -2.7988e-01,\n",
            "           5.8756e-02,  2.0424e-03, -7.5130e-01, -9.0779e-01, -9.2699e-01,\n",
            "           2.2848e-01, -6.4609e-01, -6.0584e-01, -5.2174e-01, -5.3596e-01,\n",
            "           4.2081e-01, -5.1171e-01, -9.0460e-02, -2.5988e-01, -5.5300e-01,\n",
            "           3.5079e-01,  1.0032e+00,  1.4442e-01, -4.8678e-01, -4.0837e-01,\n",
            "          -1.9268e-01, -1.1498e+00, -1.0945e+00, -6.8773e-01,  3.8678e-01,\n",
            "          -9.4970e-02,  1.1400e-01, -3.8394e-01, -2.1912e-01,  1.0550e-01,\n",
            "           3.0104e-01, -7.9097e-01, -5.6930e-01, -4.5517e-01, -1.7853e-01,\n",
            "          -3.5843e-01,  4.6095e-01,  9.8668e-01, -2.0263e-01, -3.3431e-01,\n",
            "          -4.2826e-01,  8.4598e-01,  1.4269e-01,  6.0546e-02, -1.2164e+00,\n",
            "          -2.0032e-02, -6.2261e-02, -9.8231e-01, -1.9472e-01, -5.7090e-01],\n",
            "         [ 1.1642e+00,  1.6613e+00, -6.7925e-01, -3.7455e-01, -1.6222e+00,\n",
            "          -2.5299e-01, -6.5324e-01,  2.9374e-03,  5.6250e-03, -1.3995e+00,\n",
            "          -3.0582e-01, -8.4179e-01, -2.6771e-01, -4.9547e-01, -1.4925e+00,\n",
            "          -1.3951e+00, -4.8448e-01, -1.1631e+00, -8.5781e-01, -1.5033e+00,\n",
            "          -1.4092e-01,  1.7398e-01, -9.2655e-01, -2.7173e-01,  1.8854e-01,\n",
            "          -6.4101e-01, -2.1906e-01, -7.0469e-02, -1.3935e+00, -1.9125e+00,\n",
            "          -5.0050e-01,  2.2084e-01, -3.5208e-01,  2.4499e-01, -7.5112e-01,\n",
            "          -7.6965e-01, -8.0344e-01, -3.7883e-01, -1.7138e+00,  6.2022e-01,\n",
            "          -3.6659e-01,  1.5488e-01, -6.1825e-01,  4.0788e-01,  1.7027e-01,\n",
            "          -1.0020e+00,  5.6231e-01,  2.3916e-01, -6.6693e-01, -7.4426e-01,\n",
            "           2.3622e-01,  7.0120e-01,  7.1650e-01,  1.4907e-01, -5.6999e-01,\n",
            "          -8.1014e-01,  9.1825e-01,  4.5538e-01,  2.0455e-01, -8.3555e-01,\n",
            "          -9.4799e-01,  4.8116e-01, -1.0458e+00,  3.6714e-01, -1.8081e+00],\n",
            "         [ 7.7229e-01,  9.6716e-01, -1.1015e+00, -1.2027e+00, -6.7637e-01,\n",
            "          -7.5378e-01,  4.0436e-01, -1.0906e+00, -4.6205e-01, -1.1744e+00,\n",
            "          -1.5801e+00, -1.0385e+00, -1.6995e-01,  9.5915e-01, -1.0762e-01,\n",
            "           4.7255e-01, -1.4991e-02, -1.4164e-01, -4.9926e-01, -7.7031e-01,\n",
            "           7.0395e-01, -6.6496e-01, -4.0410e-01,  5.1104e-02,  3.6092e-01,\n",
            "           6.5023e-01, -1.9751e-01, -7.0695e-02, -1.7957e-01, -6.0587e-01,\n",
            "           9.0232e-02,  3.2680e-02,  9.0719e-01, -7.5681e-01,  1.8180e-01,\n",
            "          -1.2175e-01, -1.1516e+00, -7.6338e-01, -8.9370e-01,  9.9849e-01,\n",
            "          -1.2010e-01, -4.9536e-01, -4.5423e-01,  4.3081e-01,  2.1429e-01,\n",
            "           2.6433e-01, -2.2432e-02, -8.7333e-01, -1.1162e+00, -7.7844e-01,\n",
            "          -4.0356e-01, -2.3925e-01,  1.4233e-01, -1.4650e-01,  3.9255e-02,\n",
            "          -6.7736e-01,  7.7873e-01,  1.1722e-01,  5.9948e-01, -1.3653e+00,\n",
            "          -1.4014e-01, -3.8860e-01, -1.1252e+00,  3.7759e-01, -5.8280e-01],\n",
            "         [ 5.4533e-01,  2.0446e+00, -8.4777e-01, -1.0492e+00, -1.2622e+00,\n",
            "          -5.9312e-01,  6.4782e-01,  9.0300e-02,  4.6148e-01, -1.3712e+00,\n",
            "           2.4966e-01, -1.4924e+00, -5.7184e-01, -5.0129e-01, -8.2124e-01,\n",
            "          -1.7031e+00, -6.8233e-01, -2.5186e-01, -1.0939e+00, -9.8248e-01,\n",
            "          -1.1883e+00, -2.1540e-01, -1.9727e+00, -1.2081e+00, -3.7759e-01,\n",
            "          -1.7058e+00, -5.9694e-01, -3.4047e-01, -9.7379e-01, -1.8960e+00,\n",
            "          -9.1055e-01, -8.0624e-01, -1.0026e+00, -1.3787e+00, -1.8169e+00,\n",
            "          -5.6109e-02, -1.5968e+00, -8.9530e-01, -2.2088e+00,  7.5361e-01,\n",
            "          -8.1806e-01, -4.0454e-01, -1.8056e-01,  1.3425e+00, -9.7675e-01,\n",
            "           2.5477e-01,  1.0357e+00,  3.9171e-01, -9.9557e-01,  1.1888e-01,\n",
            "           8.4718e-01, -1.6059e+00,  2.4068e-01,  7.5017e-01, -9.9189e-01,\n",
            "          -9.0575e-01,  3.7788e-01,  5.9699e-01,  2.3085e-02, -3.5115e-01,\n",
            "          -1.0802e+00, -1.5128e-01, -1.0956e+00,  4.9171e-01, -7.8917e-01],\n",
            "         [-2.1248e-01,  2.5657e+00, -2.5379e+00, -2.7971e+00, -2.0838e+00,\n",
            "          -1.0868e+00,  7.5845e-01, -2.0108e+00, -6.1243e-01, -3.6840e+00,\n",
            "          -6.5415e-01, -1.1198e+00, -1.6486e+00, -1.4617e+00, -1.6006e+00,\n",
            "          -1.9507e+00, -2.1657e+00, -1.3244e+00, -3.0632e+00, -2.3487e+00,\n",
            "          -2.0707e+00, -1.0776e+00, -3.1331e+00, -2.2773e+00, -1.3743e+00,\n",
            "          -1.8735e+00, -1.5200e+00, -1.2314e+00, -2.4722e+00, -3.1024e+00,\n",
            "          -1.4804e+00, -2.1880e+00, -1.0227e+00, -3.1163e+00, -2.6711e+00,\n",
            "          -1.5243e+00, -3.2660e+00, -2.4155e+00, -3.7520e+00,  1.1507e+00,\n",
            "          -1.3292e+00,  5.1188e-01,  2.1619e+00,  1.8537e+00, -1.7113e+00,\n",
            "           1.0283e+00,  1.0280e+00, -8.8460e-01, -2.7510e+00, -3.4709e-01,\n",
            "           7.5076e-01, -7.7539e-01,  1.4691e+00,  1.5720e+00, -4.9943e-01,\n",
            "          -2.4740e+00,  1.2889e-01,  8.1301e-01,  1.2508e+00,  1.7239e-01,\n",
            "          -6.2515e-01, -6.5416e-01, -2.7185e+00, -7.3026e-01, -2.9167e+00]]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>), torch.Size([1, 5, 65])\n",
            "logits_after =tensor([[-0.2125,  2.5657, -2.5379, -2.7971, -2.0838, -1.0868,  0.7585, -2.0108,\n",
            "         -0.6124, -3.6840, -0.6541, -1.1198, -1.6486, -1.4617, -1.6006, -1.9507,\n",
            "         -2.1657, -1.3244, -3.0632, -2.3487, -2.0707, -1.0776, -3.1331, -2.2773,\n",
            "         -1.3743, -1.8735, -1.5200, -1.2314, -2.4722, -3.1024, -1.4804, -2.1880,\n",
            "         -1.0227, -3.1163, -2.6711, -1.5243, -3.2660, -2.4155, -3.7520,  1.1507,\n",
            "         -1.3292,  0.5119,  2.1619,  1.8537, -1.7113,  1.0283,  1.0280, -0.8846,\n",
            "         -2.7510, -0.3471,  0.7508, -0.7754,  1.4691,  1.5720, -0.4994, -2.4740,\n",
            "          0.1289,  0.8130,  1.2508,  0.1724, -0.6252, -0.6542, -2.7185, -0.7303,\n",
            "         -2.9167]], device='cuda:0', grad_fn=<SliceBackward0>), torch.Size([1, 65])\n",
            "tensor([[0.0113, 0.1819, 0.0011, 0.0009, 0.0017, 0.0047, 0.0299, 0.0019, 0.0076,\n",
            "         0.0004, 0.0073, 0.0046, 0.0027, 0.0032, 0.0028, 0.0020, 0.0016, 0.0037,\n",
            "         0.0007, 0.0013, 0.0018, 0.0048, 0.0006, 0.0014, 0.0035, 0.0021, 0.0031,\n",
            "         0.0041, 0.0012, 0.0006, 0.0032, 0.0016, 0.0050, 0.0006, 0.0010, 0.0030,\n",
            "         0.0005, 0.0012, 0.0003, 0.0442, 0.0037, 0.0233, 0.1215, 0.0893, 0.0025,\n",
            "         0.0391, 0.0391, 0.0058, 0.0009, 0.0099, 0.0296, 0.0064, 0.0608, 0.0673,\n",
            "         0.0085, 0.0012, 0.0159, 0.0315, 0.0488, 0.0166, 0.0075, 0.0073, 0.0009,\n",
            "         0.0067, 0.0008]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[58]], device='cuda:0')\n",
            "logits_before =tensor([[[ 1.8752e-01,  2.0979e-01, -1.2989e+00, -7.9388e-01, -6.3770e-01,\n",
            "          -5.8339e-01, -1.4268e-01, -1.3647e+00, -8.2792e-01, -9.1511e-01,\n",
            "          -7.9475e-01, -1.2249e+00, -4.0322e-01,  4.9877e-01, -2.7988e-01,\n",
            "           5.8756e-02,  2.0424e-03, -7.5130e-01, -9.0779e-01, -9.2699e-01,\n",
            "           2.2848e-01, -6.4609e-01, -6.0584e-01, -5.2174e-01, -5.3596e-01,\n",
            "           4.2081e-01, -5.1171e-01, -9.0460e-02, -2.5988e-01, -5.5300e-01,\n",
            "           3.5079e-01,  1.0032e+00,  1.4442e-01, -4.8678e-01, -4.0837e-01,\n",
            "          -1.9268e-01, -1.1498e+00, -1.0945e+00, -6.8773e-01,  3.8678e-01,\n",
            "          -9.4970e-02,  1.1400e-01, -3.8394e-01, -2.1912e-01,  1.0550e-01,\n",
            "           3.0104e-01, -7.9097e-01, -5.6930e-01, -4.5517e-01, -1.7853e-01,\n",
            "          -3.5843e-01,  4.6095e-01,  9.8668e-01, -2.0263e-01, -3.3431e-01,\n",
            "          -4.2826e-01,  8.4598e-01,  1.4269e-01,  6.0546e-02, -1.2164e+00,\n",
            "          -2.0032e-02, -6.2261e-02, -9.8231e-01, -1.9472e-01, -5.7090e-01],\n",
            "         [ 1.1642e+00,  1.6613e+00, -6.7925e-01, -3.7455e-01, -1.6222e+00,\n",
            "          -2.5299e-01, -6.5324e-01,  2.9374e-03,  5.6250e-03, -1.3995e+00,\n",
            "          -3.0582e-01, -8.4179e-01, -2.6771e-01, -4.9547e-01, -1.4925e+00,\n",
            "          -1.3951e+00, -4.8448e-01, -1.1631e+00, -8.5781e-01, -1.5033e+00,\n",
            "          -1.4092e-01,  1.7398e-01, -9.2655e-01, -2.7173e-01,  1.8854e-01,\n",
            "          -6.4101e-01, -2.1906e-01, -7.0469e-02, -1.3935e+00, -1.9125e+00,\n",
            "          -5.0050e-01,  2.2084e-01, -3.5208e-01,  2.4499e-01, -7.5112e-01,\n",
            "          -7.6965e-01, -8.0344e-01, -3.7883e-01, -1.7138e+00,  6.2022e-01,\n",
            "          -3.6659e-01,  1.5488e-01, -6.1825e-01,  4.0788e-01,  1.7027e-01,\n",
            "          -1.0020e+00,  5.6231e-01,  2.3916e-01, -6.6693e-01, -7.4426e-01,\n",
            "           2.3622e-01,  7.0120e-01,  7.1650e-01,  1.4907e-01, -5.6999e-01,\n",
            "          -8.1014e-01,  9.1825e-01,  4.5538e-01,  2.0455e-01, -8.3555e-01,\n",
            "          -9.4799e-01,  4.8116e-01, -1.0458e+00,  3.6714e-01, -1.8081e+00],\n",
            "         [ 7.7229e-01,  9.6716e-01, -1.1015e+00, -1.2027e+00, -6.7637e-01,\n",
            "          -7.5378e-01,  4.0436e-01, -1.0906e+00, -4.6205e-01, -1.1744e+00,\n",
            "          -1.5801e+00, -1.0385e+00, -1.6995e-01,  9.5915e-01, -1.0762e-01,\n",
            "           4.7255e-01, -1.4991e-02, -1.4164e-01, -4.9926e-01, -7.7031e-01,\n",
            "           7.0395e-01, -6.6496e-01, -4.0410e-01,  5.1104e-02,  3.6092e-01,\n",
            "           6.5023e-01, -1.9751e-01, -7.0695e-02, -1.7957e-01, -6.0587e-01,\n",
            "           9.0232e-02,  3.2680e-02,  9.0719e-01, -7.5681e-01,  1.8180e-01,\n",
            "          -1.2175e-01, -1.1516e+00, -7.6338e-01, -8.9370e-01,  9.9849e-01,\n",
            "          -1.2010e-01, -4.9536e-01, -4.5423e-01,  4.3081e-01,  2.1429e-01,\n",
            "           2.6433e-01, -2.2432e-02, -8.7333e-01, -1.1162e+00, -7.7844e-01,\n",
            "          -4.0356e-01, -2.3925e-01,  1.4233e-01, -1.4650e-01,  3.9255e-02,\n",
            "          -6.7736e-01,  7.7873e-01,  1.1722e-01,  5.9948e-01, -1.3653e+00,\n",
            "          -1.4014e-01, -3.8860e-01, -1.1252e+00,  3.7759e-01, -5.8280e-01],\n",
            "         [ 5.4533e-01,  2.0446e+00, -8.4777e-01, -1.0492e+00, -1.2622e+00,\n",
            "          -5.9312e-01,  6.4782e-01,  9.0300e-02,  4.6148e-01, -1.3712e+00,\n",
            "           2.4966e-01, -1.4924e+00, -5.7184e-01, -5.0129e-01, -8.2124e-01,\n",
            "          -1.7031e+00, -6.8233e-01, -2.5186e-01, -1.0939e+00, -9.8248e-01,\n",
            "          -1.1883e+00, -2.1540e-01, -1.9727e+00, -1.2081e+00, -3.7759e-01,\n",
            "          -1.7058e+00, -5.9694e-01, -3.4047e-01, -9.7379e-01, -1.8960e+00,\n",
            "          -9.1055e-01, -8.0624e-01, -1.0026e+00, -1.3787e+00, -1.8169e+00,\n",
            "          -5.6109e-02, -1.5968e+00, -8.9530e-01, -2.2088e+00,  7.5361e-01,\n",
            "          -8.1806e-01, -4.0454e-01, -1.8056e-01,  1.3425e+00, -9.7675e-01,\n",
            "           2.5477e-01,  1.0357e+00,  3.9171e-01, -9.9557e-01,  1.1888e-01,\n",
            "           8.4718e-01, -1.6059e+00,  2.4068e-01,  7.5017e-01, -9.9189e-01,\n",
            "          -9.0575e-01,  3.7788e-01,  5.9699e-01,  2.3085e-02, -3.5115e-01,\n",
            "          -1.0802e+00, -1.5128e-01, -1.0956e+00,  4.9171e-01, -7.8917e-01],\n",
            "         [-2.1248e-01,  2.5657e+00, -2.5379e+00, -2.7971e+00, -2.0838e+00,\n",
            "          -1.0868e+00,  7.5845e-01, -2.0108e+00, -6.1243e-01, -3.6840e+00,\n",
            "          -6.5415e-01, -1.1198e+00, -1.6486e+00, -1.4617e+00, -1.6006e+00,\n",
            "          -1.9507e+00, -2.1657e+00, -1.3244e+00, -3.0632e+00, -2.3487e+00,\n",
            "          -2.0707e+00, -1.0776e+00, -3.1331e+00, -2.2773e+00, -1.3743e+00,\n",
            "          -1.8735e+00, -1.5200e+00, -1.2314e+00, -2.4722e+00, -3.1024e+00,\n",
            "          -1.4804e+00, -2.1880e+00, -1.0227e+00, -3.1163e+00, -2.6711e+00,\n",
            "          -1.5243e+00, -3.2660e+00, -2.4155e+00, -3.7520e+00,  1.1507e+00,\n",
            "          -1.3292e+00,  5.1188e-01,  2.1619e+00,  1.8537e+00, -1.7113e+00,\n",
            "           1.0283e+00,  1.0280e+00, -8.8460e-01, -2.7510e+00, -3.4709e-01,\n",
            "           7.5076e-01, -7.7539e-01,  1.4691e+00,  1.5720e+00, -4.9943e-01,\n",
            "          -2.4740e+00,  1.2889e-01,  8.1301e-01,  1.2508e+00,  1.7239e-01,\n",
            "          -6.2515e-01, -6.5416e-01, -2.7185e+00, -7.3026e-01, -2.9167e+00],\n",
            "         [ 5.8583e-01,  2.6904e+00, -1.7760e+00, -2.8888e+00, -2.2442e+00,\n",
            "          -5.3424e-01,  1.0439e-01, -1.3995e+00, -1.0593e-01, -2.3143e+00,\n",
            "          -2.1489e-01, -1.2292e+00, -2.2524e+00, -1.0570e+00, -2.1616e+00,\n",
            "          -1.9028e+00, -2.4261e+00, -1.1745e+00, -2.5183e+00, -2.1168e+00,\n",
            "          -2.9236e+00, -5.1329e-01, -2.4779e+00, -1.8966e+00, -1.1502e+00,\n",
            "          -1.7268e+00, -1.8588e+00, -1.8986e+00, -2.4173e+00, -5.0356e+00,\n",
            "          -1.4895e+00, -2.1788e+00, -1.8732e+00, -2.0797e+00, -2.4030e+00,\n",
            "          -2.0260e+00, -4.0289e+00, -2.1429e+00, -2.8461e+00,  1.5648e-01,\n",
            "          -7.0483e-01, -2.8295e-01,  3.4618e-01,  1.5072e+00,  1.6566e-01,\n",
            "          -1.3725e+00,  2.7843e+00,  1.3432e+00, -2.4628e+00, -2.0032e+00,\n",
            "           5.4883e-01,  4.0017e-01, -2.2988e-01,  1.5387e+00, -1.2690e+00,\n",
            "          -2.2281e+00,  7.4113e-01,  8.9549e-01,  1.5946e-01, -4.6468e-01,\n",
            "          -1.6561e+00, -4.6280e-02, -2.5931e+00, -1.6517e-01, -2.5498e+00]]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>), torch.Size([1, 6, 65])\n",
            "logits_after =tensor([[ 0.5858,  2.6904, -1.7760, -2.8888, -2.2442, -0.5342,  0.1044, -1.3995,\n",
            "         -0.1059, -2.3143, -0.2149, -1.2292, -2.2524, -1.0570, -2.1616, -1.9028,\n",
            "         -2.4261, -1.1745, -2.5183, -2.1168, -2.9236, -0.5133, -2.4779, -1.8966,\n",
            "         -1.1502, -1.7268, -1.8588, -1.8986, -2.4173, -5.0356, -1.4895, -2.1788,\n",
            "         -1.8732, -2.0797, -2.4030, -2.0260, -4.0289, -2.1429, -2.8461,  0.1565,\n",
            "         -0.7048, -0.2829,  0.3462,  1.5072,  0.1657, -1.3725,  2.7843,  1.3432,\n",
            "         -2.4628, -2.0032,  0.5488,  0.4002, -0.2299,  1.5387, -1.2690, -2.2281,\n",
            "          0.7411,  0.8955,  0.1595, -0.4647, -1.6561, -0.0463, -2.5931, -0.1652,\n",
            "         -2.5498]], device='cuda:0', grad_fn=<SliceBackward0>), torch.Size([1, 65])\n",
            "tensor([[2.4740e-02, 2.0297e-01, 2.3316e-03, 7.6632e-04, 1.4599e-03, 8.0716e-03,\n",
            "         1.5287e-02, 3.3977e-03, 1.2387e-02, 1.3611e-03, 1.1108e-02, 4.0286e-03,\n",
            "         1.4481e-03, 4.7854e-03, 1.5856e-03, 2.0540e-03, 1.2172e-03, 4.2549e-03,\n",
            "         1.1100e-03, 1.6583e-03, 7.4006e-04, 8.2425e-03, 1.1557e-03, 2.0669e-03,\n",
            "         4.3596e-03, 2.4492e-03, 2.1463e-03, 2.0626e-03, 1.2279e-03, 8.9548e-05,\n",
            "         3.1052e-03, 1.5587e-03, 2.1158e-03, 1.7210e-03, 1.2455e-03, 1.8159e-03,\n",
            "         2.4505e-04, 1.6155e-03, 7.9974e-04, 1.6104e-02, 6.8057e-03, 1.0378e-02,\n",
            "         1.9468e-02, 6.2164e-02, 1.6253e-02, 3.4908e-03, 2.2294e-01, 5.2763e-02,\n",
            "         1.1733e-03, 1.8577e-03, 2.3841e-02, 2.0548e-02, 1.0943e-02, 6.4151e-02,\n",
            "         3.8712e-03, 1.4836e-03, 2.8897e-02, 3.3720e-02, 1.6152e-02, 8.6530e-03,\n",
            "         2.6286e-03, 1.3149e-02, 1.0300e-03, 1.1675e-02, 1.0755e-03]],\n",
            "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[1]], device='cuda:0')\n",
            "logits_before =tensor([[[ 1.8752e-01,  2.0979e-01, -1.2989e+00, -7.9388e-01, -6.3770e-01,\n",
            "          -5.8339e-01, -1.4268e-01, -1.3647e+00, -8.2792e-01, -9.1511e-01,\n",
            "          -7.9475e-01, -1.2249e+00, -4.0322e-01,  4.9877e-01, -2.7988e-01,\n",
            "           5.8756e-02,  2.0424e-03, -7.5130e-01, -9.0779e-01, -9.2699e-01,\n",
            "           2.2848e-01, -6.4609e-01, -6.0584e-01, -5.2174e-01, -5.3596e-01,\n",
            "           4.2081e-01, -5.1171e-01, -9.0460e-02, -2.5988e-01, -5.5300e-01,\n",
            "           3.5079e-01,  1.0032e+00,  1.4442e-01, -4.8678e-01, -4.0837e-01,\n",
            "          -1.9268e-01, -1.1498e+00, -1.0945e+00, -6.8773e-01,  3.8678e-01,\n",
            "          -9.4970e-02,  1.1400e-01, -3.8394e-01, -2.1912e-01,  1.0550e-01,\n",
            "           3.0104e-01, -7.9097e-01, -5.6930e-01, -4.5517e-01, -1.7853e-01,\n",
            "          -3.5843e-01,  4.6095e-01,  9.8668e-01, -2.0263e-01, -3.3431e-01,\n",
            "          -4.2826e-01,  8.4598e-01,  1.4269e-01,  6.0546e-02, -1.2164e+00,\n",
            "          -2.0032e-02, -6.2261e-02, -9.8231e-01, -1.9472e-01, -5.7090e-01],\n",
            "         [ 1.1642e+00,  1.6613e+00, -6.7925e-01, -3.7455e-01, -1.6222e+00,\n",
            "          -2.5299e-01, -6.5324e-01,  2.9374e-03,  5.6250e-03, -1.3995e+00,\n",
            "          -3.0582e-01, -8.4179e-01, -2.6771e-01, -4.9547e-01, -1.4925e+00,\n",
            "          -1.3951e+00, -4.8448e-01, -1.1631e+00, -8.5781e-01, -1.5033e+00,\n",
            "          -1.4092e-01,  1.7398e-01, -9.2655e-01, -2.7173e-01,  1.8854e-01,\n",
            "          -6.4101e-01, -2.1906e-01, -7.0469e-02, -1.3935e+00, -1.9125e+00,\n",
            "          -5.0050e-01,  2.2084e-01, -3.5208e-01,  2.4499e-01, -7.5112e-01,\n",
            "          -7.6965e-01, -8.0344e-01, -3.7883e-01, -1.7138e+00,  6.2022e-01,\n",
            "          -3.6659e-01,  1.5488e-01, -6.1825e-01,  4.0788e-01,  1.7027e-01,\n",
            "          -1.0020e+00,  5.6231e-01,  2.3916e-01, -6.6693e-01, -7.4426e-01,\n",
            "           2.3622e-01,  7.0120e-01,  7.1650e-01,  1.4907e-01, -5.6999e-01,\n",
            "          -8.1014e-01,  9.1825e-01,  4.5538e-01,  2.0455e-01, -8.3555e-01,\n",
            "          -9.4799e-01,  4.8116e-01, -1.0458e+00,  3.6714e-01, -1.8081e+00],\n",
            "         [ 7.7229e-01,  9.6716e-01, -1.1015e+00, -1.2027e+00, -6.7637e-01,\n",
            "          -7.5378e-01,  4.0436e-01, -1.0906e+00, -4.6205e-01, -1.1744e+00,\n",
            "          -1.5801e+00, -1.0385e+00, -1.6995e-01,  9.5915e-01, -1.0762e-01,\n",
            "           4.7255e-01, -1.4991e-02, -1.4164e-01, -4.9926e-01, -7.7031e-01,\n",
            "           7.0395e-01, -6.6496e-01, -4.0410e-01,  5.1104e-02,  3.6092e-01,\n",
            "           6.5023e-01, -1.9751e-01, -7.0695e-02, -1.7957e-01, -6.0587e-01,\n",
            "           9.0232e-02,  3.2680e-02,  9.0719e-01, -7.5681e-01,  1.8180e-01,\n",
            "          -1.2175e-01, -1.1516e+00, -7.6338e-01, -8.9370e-01,  9.9849e-01,\n",
            "          -1.2010e-01, -4.9536e-01, -4.5423e-01,  4.3081e-01,  2.1429e-01,\n",
            "           2.6433e-01, -2.2432e-02, -8.7333e-01, -1.1162e+00, -7.7844e-01,\n",
            "          -4.0356e-01, -2.3925e-01,  1.4233e-01, -1.4650e-01,  3.9255e-02,\n",
            "          -6.7736e-01,  7.7873e-01,  1.1722e-01,  5.9948e-01, -1.3653e+00,\n",
            "          -1.4014e-01, -3.8860e-01, -1.1252e+00,  3.7759e-01, -5.8280e-01],\n",
            "         [ 5.4533e-01,  2.0446e+00, -8.4777e-01, -1.0492e+00, -1.2622e+00,\n",
            "          -5.9312e-01,  6.4782e-01,  9.0300e-02,  4.6148e-01, -1.3712e+00,\n",
            "           2.4966e-01, -1.4924e+00, -5.7184e-01, -5.0129e-01, -8.2124e-01,\n",
            "          -1.7031e+00, -6.8233e-01, -2.5186e-01, -1.0939e+00, -9.8248e-01,\n",
            "          -1.1883e+00, -2.1540e-01, -1.9727e+00, -1.2081e+00, -3.7759e-01,\n",
            "          -1.7058e+00, -5.9694e-01, -3.4047e-01, -9.7379e-01, -1.8960e+00,\n",
            "          -9.1055e-01, -8.0624e-01, -1.0026e+00, -1.3787e+00, -1.8169e+00,\n",
            "          -5.6109e-02, -1.5968e+00, -8.9530e-01, -2.2088e+00,  7.5361e-01,\n",
            "          -8.1806e-01, -4.0454e-01, -1.8056e-01,  1.3425e+00, -9.7675e-01,\n",
            "           2.5477e-01,  1.0357e+00,  3.9171e-01, -9.9557e-01,  1.1888e-01,\n",
            "           8.4718e-01, -1.6059e+00,  2.4068e-01,  7.5017e-01, -9.9189e-01,\n",
            "          -9.0575e-01,  3.7788e-01,  5.9699e-01,  2.3085e-02, -3.5115e-01,\n",
            "          -1.0802e+00, -1.5128e-01, -1.0956e+00,  4.9171e-01, -7.8917e-01],\n",
            "         [-2.1248e-01,  2.5657e+00, -2.5379e+00, -2.7971e+00, -2.0838e+00,\n",
            "          -1.0868e+00,  7.5845e-01, -2.0108e+00, -6.1243e-01, -3.6840e+00,\n",
            "          -6.5415e-01, -1.1198e+00, -1.6486e+00, -1.4617e+00, -1.6006e+00,\n",
            "          -1.9507e+00, -2.1657e+00, -1.3244e+00, -3.0632e+00, -2.3487e+00,\n",
            "          -2.0707e+00, -1.0776e+00, -3.1331e+00, -2.2773e+00, -1.3743e+00,\n",
            "          -1.8735e+00, -1.5200e+00, -1.2314e+00, -2.4722e+00, -3.1024e+00,\n",
            "          -1.4804e+00, -2.1880e+00, -1.0227e+00, -3.1163e+00, -2.6711e+00,\n",
            "          -1.5243e+00, -3.2660e+00, -2.4155e+00, -3.7520e+00,  1.1507e+00,\n",
            "          -1.3292e+00,  5.1188e-01,  2.1619e+00,  1.8537e+00, -1.7113e+00,\n",
            "           1.0283e+00,  1.0280e+00, -8.8460e-01, -2.7510e+00, -3.4709e-01,\n",
            "           7.5076e-01, -7.7539e-01,  1.4691e+00,  1.5720e+00, -4.9943e-01,\n",
            "          -2.4740e+00,  1.2889e-01,  8.1301e-01,  1.2508e+00,  1.7239e-01,\n",
            "          -6.2515e-01, -6.5416e-01, -2.7185e+00, -7.3026e-01, -2.9167e+00],\n",
            "         [ 5.8583e-01,  2.6904e+00, -1.7760e+00, -2.8888e+00, -2.2442e+00,\n",
            "          -5.3424e-01,  1.0439e-01, -1.3995e+00, -1.0593e-01, -2.3143e+00,\n",
            "          -2.1489e-01, -1.2292e+00, -2.2524e+00, -1.0570e+00, -2.1616e+00,\n",
            "          -1.9028e+00, -2.4261e+00, -1.1745e+00, -2.5183e+00, -2.1168e+00,\n",
            "          -2.9236e+00, -5.1329e-01, -2.4779e+00, -1.8966e+00, -1.1502e+00,\n",
            "          -1.7268e+00, -1.8588e+00, -1.8986e+00, -2.4173e+00, -5.0356e+00,\n",
            "          -1.4895e+00, -2.1788e+00, -1.8732e+00, -2.0797e+00, -2.4030e+00,\n",
            "          -2.0260e+00, -4.0289e+00, -2.1429e+00, -2.8461e+00,  1.5648e-01,\n",
            "          -7.0483e-01, -2.8295e-01,  3.4618e-01,  1.5072e+00,  1.6566e-01,\n",
            "          -1.3725e+00,  2.7843e+00,  1.3432e+00, -2.4628e+00, -2.0032e+00,\n",
            "           5.4883e-01,  4.0017e-01, -2.2988e-01,  1.5387e+00, -1.2690e+00,\n",
            "          -2.2281e+00,  7.4113e-01,  8.9549e-01,  1.5946e-01, -4.6468e-01,\n",
            "          -1.6561e+00, -4.6280e-02, -2.5931e+00, -1.6517e-01, -2.5498e+00],\n",
            "         [ 7.2870e-01,  1.2900e+00, -2.4740e+00, -3.5096e+00, -2.4419e+00,\n",
            "          -9.6527e-01, -1.6835e-01, -2.9223e+00, -1.4639e+00, -2.4881e+00,\n",
            "          -1.6301e+00, -1.9365e+00, -2.0007e+00, -1.2120e+00, -1.4995e+00,\n",
            "          -1.3994e+00, -2.3064e+00, -1.5338e+00, -1.5429e+00, -2.0481e+00,\n",
            "          -2.9453e+00, -9.5335e-02, -3.2047e+00, -2.4334e+00, -8.8358e-01,\n",
            "          -2.0673e+00, -1.8061e+00, -1.3182e+00, -2.9054e+00, -3.6426e+00,\n",
            "          -1.9397e+00, -1.7683e+00, -1.1763e+00, -2.5520e+00, -1.9926e+00,\n",
            "          -1.2689e+00, -4.2997e+00, -2.0375e+00, -4.0952e+00,  1.5348e+00,\n",
            "           1.2203e+00,  8.9385e-01,  7.0878e-01,  1.1802e+00,  5.7765e-01,\n",
            "          -3.5175e-01,  1.5158e+00,  1.4444e+00, -2.1856e+00, -1.7674e+00,\n",
            "           1.7532e-01,  1.3604e+00,  2.5404e-01,  1.5229e+00,  3.3654e-01,\n",
            "          -1.9408e+00,  1.2121e-02,  1.7570e+00,  2.6976e+00, -1.0283e+00,\n",
            "          -1.0118e+00,  1.2115e+00, -2.7341e+00,  4.9398e-01, -2.7957e+00]]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>), torch.Size([1, 7, 65])\n",
            "logits_after =tensor([[ 0.7287,  1.2900, -2.4740, -3.5096, -2.4419, -0.9653, -0.1683, -2.9223,\n",
            "         -1.4639, -2.4881, -1.6301, -1.9365, -2.0007, -1.2120, -1.4995, -1.3994,\n",
            "         -2.3064, -1.5338, -1.5429, -2.0481, -2.9453, -0.0953, -3.2047, -2.4334,\n",
            "         -0.8836, -2.0673, -1.8061, -1.3182, -2.9054, -3.6426, -1.9397, -1.7683,\n",
            "         -1.1763, -2.5520, -1.9926, -1.2689, -4.2997, -2.0375, -4.0952,  1.5348,\n",
            "          1.2203,  0.8939,  0.7088,  1.1802,  0.5777, -0.3517,  1.5158,  1.4444,\n",
            "         -2.1856, -1.7674,  0.1753,  1.3604,  0.2540,  1.5229,  0.3365, -1.9408,\n",
            "          0.0121,  1.7570,  2.6976, -1.0283, -1.0118,  1.2115, -2.7341,  0.4940,\n",
            "         -2.7957]], device='cuda:0', grad_fn=<SliceBackward0>), torch.Size([1, 65])\n",
            "tensor([[2.5857e-02, 4.5327e-02, 1.0511e-03, 3.7317e-04, 1.0854e-03, 4.7523e-03,\n",
            "         1.0544e-02, 6.7139e-04, 2.8862e-03, 1.0365e-03, 2.4443e-03, 1.7994e-03,\n",
            "         1.6874e-03, 3.7132e-03, 2.7854e-03, 3.0788e-03, 1.2429e-03, 2.6914e-03,\n",
            "         2.6672e-03, 1.6092e-03, 6.5615e-04, 1.1342e-02, 5.0620e-04, 1.0947e-03,\n",
            "         5.1568e-03, 1.5787e-03, 2.0498e-03, 3.3391e-03, 6.8279e-04, 3.2671e-04,\n",
            "         1.7936e-03, 2.1289e-03, 3.8482e-03, 9.7227e-04, 1.7011e-03, 3.5078e-03,\n",
            "         1.6934e-04, 1.6264e-03, 2.0778e-04, 5.7901e-02, 4.2273e-02, 3.0500e-02,\n",
            "         2.5347e-02, 4.0612e-02, 2.2232e-02, 8.7770e-03, 5.6808e-02, 5.2894e-02,\n",
            "         1.4026e-03, 2.1307e-03, 1.4868e-02, 4.8633e-02, 1.6086e-02, 5.7214e-02,\n",
            "         1.7469e-02, 1.7916e-03, 1.2629e-02, 7.2301e-02, 1.8522e-01, 4.4618e-03,\n",
            "         4.5362e-03, 4.1904e-02, 8.1042e-04, 2.0447e-02, 7.6199e-04]],\n",
            "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[47]], device='cuda:0')\n",
            "logits_before =tensor([[[ 1.8752e-01,  2.0979e-01, -1.2989e+00, -7.9388e-01, -6.3770e-01,\n",
            "          -5.8339e-01, -1.4268e-01, -1.3647e+00, -8.2792e-01, -9.1511e-01,\n",
            "          -7.9475e-01, -1.2249e+00, -4.0322e-01,  4.9877e-01, -2.7988e-01,\n",
            "           5.8756e-02,  2.0424e-03, -7.5130e-01, -9.0779e-01, -9.2699e-01,\n",
            "           2.2848e-01, -6.4609e-01, -6.0584e-01, -5.2174e-01, -5.3596e-01,\n",
            "           4.2081e-01, -5.1171e-01, -9.0460e-02, -2.5988e-01, -5.5300e-01,\n",
            "           3.5079e-01,  1.0032e+00,  1.4442e-01, -4.8678e-01, -4.0837e-01,\n",
            "          -1.9268e-01, -1.1498e+00, -1.0945e+00, -6.8773e-01,  3.8678e-01,\n",
            "          -9.4970e-02,  1.1400e-01, -3.8394e-01, -2.1912e-01,  1.0550e-01,\n",
            "           3.0104e-01, -7.9097e-01, -5.6930e-01, -4.5517e-01, -1.7853e-01,\n",
            "          -3.5843e-01,  4.6095e-01,  9.8668e-01, -2.0263e-01, -3.3431e-01,\n",
            "          -4.2826e-01,  8.4598e-01,  1.4269e-01,  6.0546e-02, -1.2164e+00,\n",
            "          -2.0032e-02, -6.2261e-02, -9.8231e-01, -1.9472e-01, -5.7090e-01],\n",
            "         [ 1.1642e+00,  1.6613e+00, -6.7925e-01, -3.7455e-01, -1.6222e+00,\n",
            "          -2.5299e-01, -6.5324e-01,  2.9374e-03,  5.6250e-03, -1.3995e+00,\n",
            "          -3.0582e-01, -8.4179e-01, -2.6771e-01, -4.9547e-01, -1.4925e+00,\n",
            "          -1.3951e+00, -4.8448e-01, -1.1631e+00, -8.5781e-01, -1.5033e+00,\n",
            "          -1.4092e-01,  1.7398e-01, -9.2655e-01, -2.7173e-01,  1.8854e-01,\n",
            "          -6.4101e-01, -2.1906e-01, -7.0469e-02, -1.3935e+00, -1.9125e+00,\n",
            "          -5.0050e-01,  2.2084e-01, -3.5208e-01,  2.4499e-01, -7.5112e-01,\n",
            "          -7.6965e-01, -8.0344e-01, -3.7883e-01, -1.7138e+00,  6.2022e-01,\n",
            "          -3.6659e-01,  1.5488e-01, -6.1825e-01,  4.0788e-01,  1.7027e-01,\n",
            "          -1.0020e+00,  5.6231e-01,  2.3916e-01, -6.6693e-01, -7.4426e-01,\n",
            "           2.3622e-01,  7.0120e-01,  7.1650e-01,  1.4907e-01, -5.6999e-01,\n",
            "          -8.1014e-01,  9.1825e-01,  4.5538e-01,  2.0455e-01, -8.3555e-01,\n",
            "          -9.4799e-01,  4.8116e-01, -1.0458e+00,  3.6714e-01, -1.8081e+00],\n",
            "         [ 7.7229e-01,  9.6716e-01, -1.1015e+00, -1.2027e+00, -6.7637e-01,\n",
            "          -7.5378e-01,  4.0436e-01, -1.0906e+00, -4.6205e-01, -1.1744e+00,\n",
            "          -1.5801e+00, -1.0385e+00, -1.6995e-01,  9.5915e-01, -1.0762e-01,\n",
            "           4.7255e-01, -1.4991e-02, -1.4164e-01, -4.9926e-01, -7.7031e-01,\n",
            "           7.0395e-01, -6.6496e-01, -4.0410e-01,  5.1104e-02,  3.6092e-01,\n",
            "           6.5023e-01, -1.9751e-01, -7.0695e-02, -1.7957e-01, -6.0587e-01,\n",
            "           9.0232e-02,  3.2680e-02,  9.0719e-01, -7.5681e-01,  1.8180e-01,\n",
            "          -1.2175e-01, -1.1516e+00, -7.6338e-01, -8.9370e-01,  9.9849e-01,\n",
            "          -1.2010e-01, -4.9536e-01, -4.5423e-01,  4.3081e-01,  2.1429e-01,\n",
            "           2.6433e-01, -2.2432e-02, -8.7333e-01, -1.1162e+00, -7.7844e-01,\n",
            "          -4.0356e-01, -2.3925e-01,  1.4233e-01, -1.4650e-01,  3.9255e-02,\n",
            "          -6.7736e-01,  7.7873e-01,  1.1722e-01,  5.9948e-01, -1.3653e+00,\n",
            "          -1.4014e-01, -3.8860e-01, -1.1252e+00,  3.7759e-01, -5.8280e-01],\n",
            "         [ 5.4533e-01,  2.0446e+00, -8.4777e-01, -1.0492e+00, -1.2622e+00,\n",
            "          -5.9312e-01,  6.4782e-01,  9.0300e-02,  4.6148e-01, -1.3712e+00,\n",
            "           2.4966e-01, -1.4924e+00, -5.7184e-01, -5.0129e-01, -8.2124e-01,\n",
            "          -1.7031e+00, -6.8233e-01, -2.5186e-01, -1.0939e+00, -9.8248e-01,\n",
            "          -1.1883e+00, -2.1540e-01, -1.9727e+00, -1.2081e+00, -3.7759e-01,\n",
            "          -1.7058e+00, -5.9694e-01, -3.4047e-01, -9.7379e-01, -1.8960e+00,\n",
            "          -9.1055e-01, -8.0624e-01, -1.0026e+00, -1.3787e+00, -1.8169e+00,\n",
            "          -5.6109e-02, -1.5968e+00, -8.9530e-01, -2.2088e+00,  7.5361e-01,\n",
            "          -8.1806e-01, -4.0454e-01, -1.8056e-01,  1.3425e+00, -9.7675e-01,\n",
            "           2.5477e-01,  1.0357e+00,  3.9171e-01, -9.9557e-01,  1.1888e-01,\n",
            "           8.4718e-01, -1.6059e+00,  2.4068e-01,  7.5017e-01, -9.9189e-01,\n",
            "          -9.0575e-01,  3.7788e-01,  5.9699e-01,  2.3085e-02, -3.5115e-01,\n",
            "          -1.0802e+00, -1.5128e-01, -1.0956e+00,  4.9171e-01, -7.8917e-01],\n",
            "         [-2.1248e-01,  2.5657e+00, -2.5379e+00, -2.7971e+00, -2.0838e+00,\n",
            "          -1.0868e+00,  7.5845e-01, -2.0108e+00, -6.1243e-01, -3.6840e+00,\n",
            "          -6.5415e-01, -1.1198e+00, -1.6486e+00, -1.4617e+00, -1.6006e+00,\n",
            "          -1.9507e+00, -2.1657e+00, -1.3244e+00, -3.0632e+00, -2.3487e+00,\n",
            "          -2.0707e+00, -1.0776e+00, -3.1331e+00, -2.2773e+00, -1.3743e+00,\n",
            "          -1.8735e+00, -1.5200e+00, -1.2314e+00, -2.4722e+00, -3.1024e+00,\n",
            "          -1.4804e+00, -2.1880e+00, -1.0227e+00, -3.1163e+00, -2.6711e+00,\n",
            "          -1.5243e+00, -3.2660e+00, -2.4155e+00, -3.7520e+00,  1.1507e+00,\n",
            "          -1.3292e+00,  5.1188e-01,  2.1619e+00,  1.8537e+00, -1.7113e+00,\n",
            "           1.0283e+00,  1.0280e+00, -8.8460e-01, -2.7510e+00, -3.4709e-01,\n",
            "           7.5076e-01, -7.7539e-01,  1.4691e+00,  1.5720e+00, -4.9943e-01,\n",
            "          -2.4740e+00,  1.2889e-01,  8.1301e-01,  1.2508e+00,  1.7239e-01,\n",
            "          -6.2515e-01, -6.5416e-01, -2.7185e+00, -7.3026e-01, -2.9167e+00],\n",
            "         [ 5.8583e-01,  2.6904e+00, -1.7760e+00, -2.8888e+00, -2.2442e+00,\n",
            "          -5.3424e-01,  1.0439e-01, -1.3995e+00, -1.0593e-01, -2.3143e+00,\n",
            "          -2.1489e-01, -1.2292e+00, -2.2524e+00, -1.0570e+00, -2.1616e+00,\n",
            "          -1.9028e+00, -2.4261e+00, -1.1745e+00, -2.5183e+00, -2.1168e+00,\n",
            "          -2.9236e+00, -5.1329e-01, -2.4779e+00, -1.8966e+00, -1.1502e+00,\n",
            "          -1.7268e+00, -1.8588e+00, -1.8986e+00, -2.4173e+00, -5.0356e+00,\n",
            "          -1.4895e+00, -2.1788e+00, -1.8732e+00, -2.0797e+00, -2.4030e+00,\n",
            "          -2.0260e+00, -4.0289e+00, -2.1429e+00, -2.8461e+00,  1.5648e-01,\n",
            "          -7.0483e-01, -2.8295e-01,  3.4618e-01,  1.5072e+00,  1.6566e-01,\n",
            "          -1.3725e+00,  2.7843e+00,  1.3432e+00, -2.4628e+00, -2.0032e+00,\n",
            "           5.4883e-01,  4.0017e-01, -2.2988e-01,  1.5387e+00, -1.2690e+00,\n",
            "          -2.2281e+00,  7.4113e-01,  8.9549e-01,  1.5946e-01, -4.6468e-01,\n",
            "          -1.6561e+00, -4.6280e-02, -2.5931e+00, -1.6517e-01, -2.5498e+00],\n",
            "         [ 7.2870e-01,  1.2900e+00, -2.4740e+00, -3.5096e+00, -2.4419e+00,\n",
            "          -9.6527e-01, -1.6835e-01, -2.9223e+00, -1.4639e+00, -2.4881e+00,\n",
            "          -1.6301e+00, -1.9365e+00, -2.0007e+00, -1.2120e+00, -1.4995e+00,\n",
            "          -1.3994e+00, -2.3064e+00, -1.5338e+00, -1.5429e+00, -2.0481e+00,\n",
            "          -2.9453e+00, -9.5335e-02, -3.2047e+00, -2.4334e+00, -8.8358e-01,\n",
            "          -2.0673e+00, -1.8061e+00, -1.3182e+00, -2.9054e+00, -3.6426e+00,\n",
            "          -1.9397e+00, -1.7683e+00, -1.1763e+00, -2.5520e+00, -1.9926e+00,\n",
            "          -1.2689e+00, -4.2997e+00, -2.0375e+00, -4.0952e+00,  1.5348e+00,\n",
            "           1.2203e+00,  8.9385e-01,  7.0878e-01,  1.1802e+00,  5.7765e-01,\n",
            "          -3.5175e-01,  1.5158e+00,  1.4444e+00, -2.1856e+00, -1.7674e+00,\n",
            "           1.7532e-01,  1.3604e+00,  2.5404e-01,  1.5229e+00,  3.3654e-01,\n",
            "          -1.9408e+00,  1.2121e-02,  1.7570e+00,  2.6976e+00, -1.0283e+00,\n",
            "          -1.0118e+00,  1.2115e+00, -2.7341e+00,  4.9398e-01, -2.7957e+00],\n",
            "         [ 3.4055e-01,  1.3298e+00, -1.2466e+00, -1.9141e+00, -2.1296e+00,\n",
            "          -5.2698e-01, -2.3051e-01, -1.3542e+00, -1.1703e+00, -2.0906e+00,\n",
            "           4.5791e-02, -1.8611e+00, -8.7683e-01, -5.5991e-01, -1.8095e+00,\n",
            "          -8.1324e-01, -7.8240e-01, -1.3814e+00, -1.8553e+00, -2.0918e+00,\n",
            "          -9.5819e-01, -8.9801e-01, -1.2204e+00, -1.3508e+00, -1.1102e+00,\n",
            "          -1.5076e+00, -6.2880e-01, -9.5775e-01, -1.8114e+00, -2.0946e+00,\n",
            "          -1.2192e+00, -6.9737e-01, -2.4788e-01, -9.1071e-01, -1.5471e+00,\n",
            "          -7.5844e-01, -1.3654e+00, -1.6832e+00, -2.0969e+00, -8.5742e-02,\n",
            "          -8.4248e-01,  4.3492e-01,  4.3086e-01,  1.5218e+00, -8.9140e-01,\n",
            "           2.3701e-01,  1.2655e+00,  3.9765e-01, -1.8554e+00, -1.1228e+00,\n",
            "           9.4941e-01,  1.5383e+00,  1.6262e+00,  8.0334e-01, -1.8077e-01,\n",
            "          -1.6477e+00,  1.4639e+00,  9.5139e-01,  1.1237e+00,  9.2860e-03,\n",
            "          -2.3579e-01, -3.2569e-01, -1.7496e+00,  3.0471e-01, -2.0210e+00]]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>), torch.Size([1, 8, 65])\n",
            "logits_after =tensor([[ 0.3406,  1.3298, -1.2466, -1.9141, -2.1296, -0.5270, -0.2305, -1.3542,\n",
            "         -1.1703, -2.0906,  0.0458, -1.8611, -0.8768, -0.5599, -1.8095, -0.8132,\n",
            "         -0.7824, -1.3814, -1.8553, -2.0918, -0.9582, -0.8980, -1.2204, -1.3508,\n",
            "         -1.1102, -1.5076, -0.6288, -0.9578, -1.8114, -2.0946, -1.2192, -0.6974,\n",
            "         -0.2479, -0.9107, -1.5471, -0.7584, -1.3654, -1.6832, -2.0969, -0.0857,\n",
            "         -0.8425,  0.4349,  0.4309,  1.5218, -0.8914,  0.2370,  1.2655,  0.3976,\n",
            "         -1.8554, -1.1228,  0.9494,  1.5383,  1.6262,  0.8033, -0.1808, -1.6477,\n",
            "          1.4639,  0.9514,  1.1237,  0.0093, -0.2358, -0.3257, -1.7496,  0.3047,\n",
            "         -2.0210]], device='cuda:0', grad_fn=<SliceBackward0>), torch.Size([1, 65])\n",
            "tensor([[0.0220, 0.0592, 0.0045, 0.0023, 0.0019, 0.0092, 0.0124, 0.0040, 0.0049,\n",
            "         0.0019, 0.0164, 0.0024, 0.0065, 0.0089, 0.0026, 0.0069, 0.0072, 0.0039,\n",
            "         0.0024, 0.0019, 0.0060, 0.0064, 0.0046, 0.0041, 0.0052, 0.0035, 0.0083,\n",
            "         0.0060, 0.0026, 0.0019, 0.0046, 0.0078, 0.0122, 0.0063, 0.0033, 0.0073,\n",
            "         0.0040, 0.0029, 0.0019, 0.0144, 0.0067, 0.0242, 0.0241, 0.0717, 0.0064,\n",
            "         0.0198, 0.0555, 0.0233, 0.0024, 0.0051, 0.0405, 0.0729, 0.0796, 0.0350,\n",
            "         0.0131, 0.0030, 0.0677, 0.0405, 0.0482, 0.0158, 0.0124, 0.0113, 0.0027,\n",
            "         0.0212, 0.0021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[49]], device='cuda:0')\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bigram_v2.py\", line 143, in <module>\n",
            "    print(decode(m.generate(context, max_new_tokens=10)[0].tolist()))\n",
            "  File \"/content/bigram_v2.py\", line 106, in generate\n",
            "    print(f\"logits_before ={logits}, {logits.shape}\")\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\", line 859, in __format__\n",
            "    return object.__format__(self, format_spec)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\", line 427, in __repr__\n",
            "    return torch._tensor_str._str(self, tensor_contents=tensor_contents)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/_tensor_str.py\", line 637, in _str\n",
            "    return _str_intern(self, tensor_contents=tensor_contents)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/_tensor_str.py\", line 568, in _str_intern\n",
            "    tensor_str = _tensor_str(self, indent)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/_tensor_str.py\", line 328, in _tensor_str\n",
            "    formatter = _Formatter(get_summarized_data(self) if summarize else self)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/_tensor_str.py\", line 115, in __init__\n",
            "    nonzero_finite_vals = torch.masked_select(\n",
            "RuntimeError: CUDA error: device-side assert triggered\n",
            "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
            "CPU times: user 57.1 ms, sys: 8.06 ms, total: 65.2 ms\n",
            "Wall time: 7.16 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## self-attention implementation"
      ],
      "metadata": {
        "id": "rjM3feE9vBsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`wei = torch.zeros((T, T))` - данный шаг создает равномерное распределение важности токенов. Нам это неинтересно. Нам бы лучше знать, что некоторые токены имеют больший вес. Например, если сейчас мы на гласной, то ранее нам более интересны согласные.\n",
        "\n",
        "В общем, нужно для каждого токена назначить вес. И получить взвешенное среднее. Данную проблему решает *self-attention*\n",
        "\n",
        "*Как self-attention решает данную проблему?*\n",
        "---\n",
        "1. Каждый токен будет иметь две матрицы:\n",
        "\n",
        "    a. query - отвечает на вопрос \"Что я ищу?\"\n",
        "\n",
        "    b. key - отвечает на вопрос \"Что я содержу?\"\n",
        "\n",
        "\n",
        "И чтобы узнать взаимоотношения между векторами - нужно перемножить все запросы со всеми ключами. (то есть 8 запросов перемножаются с 8 ключами, 64 перемножения).\n",
        "\n",
        "*Запрос перемножается с каждым ключом и данное перемножение становится взвешенным средним (то есть мы для каждого токена назначаем вес, насколько этот токен важен для текущего токена?)*\n",
        "\n",
        "\n",
        "Также у нас есть еще одно значение, которое называется ЗНАЧЕНИЕ *value*\n",
        "\n",
        "`x` - это личная информация токена\n",
        "\n",
        "`value` - говорит о том, что я содержу, если я вам интересен (после перемножения query @ key)"
      ],
      "metadata": {
        "id": "Ez2dphHUwWQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##-- version4: self-attention\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B, T, C = 4, 8, 2 # batch, time, channels\n",
        "x = torch.randn((B, T, C))\n",
        "\n",
        "##-- single head in self-attention\n",
        "head_size = 16 # 2 ##-- hyperparameter\n",
        "query = nn.Linear(C, head_size, bias=False) ## веса случайные # key.weight\n",
        "key = nn.Linear(C, head_size, bias=False) ## другие веса случайные # query.weight\n",
        "value = nn.Linear(C, head_size, bias=False) ## другие веса случайные # value.weight\n",
        "# print(f\"query.weight={query.weight}\")\n",
        "# print(f\"key.weight={key.weight}\")\n",
        "##-- для каждого токена получаем запрос и ключ (пока никакой коммуникации)\n",
        "q = query(x) # (B, T, 16) ##-- матричное перемножение с фиксированными весами (1x32 --> 1x16)\n",
        "k = key(x) # (B, T, 16) ##-- матричное перемножение с фиксированными весами (1x32 --> 1x16)\n",
        "# print(f\"q={q}\")\n",
        "# print(f\"k={k}\")\n",
        "##-- коммуникация между токенами (query @ key)\n",
        "wei = q @ k.transpose(-2, -1) ##-- (B, T, 16) x (B, 16, T) -->> (B, T, T)\n",
        "# print(f\"wei[0]={wei[0]}\")\n",
        "\n",
        "\n",
        "##-- усреднение предыдущих токенов (и текущего)\n",
        "tril = torch.tril(torch.ones((T, T)))\n",
        "# wei = torch.zeros((T, T))\n",
        "wei = wei.masked_fill(tril==0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "\n",
        "##-- value\n",
        "v = value(x) # (B, T, 16) ##-- матричное перемножение с фиксированными весами (1x32 --> 1x16)\n",
        "out = wei @ v # (B, T, T) @ (B, T, 16) -->> (B, T, 16)\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbIUfqUvqhz5",
        "outputId": "f50507ea-5916-4be8-d88c-b735d368bb49"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Notes\n",
        "\n",
        "1. Attention - это механизм внимания. В нашем случае, первый токен соединен с самим собой. Второй токен - с самим собой и с первым токеном. Третий - с собой, вторым и третим. И так далее.\n",
        "\n",
        "2. Нет никакого понятия пространства. Первоначально, когда мы задаем токены, они не знают ничего друг о друге и где они находятся. Чтобы они знали - нужно добавить attention - веса для каждого токена (переменная `wei`)\n",
        "\n",
        "3. Батчи не разговаривают друг с другом. То есть у нас есть батч размера 4 и получается, что третий батч не общается ни со вторым батчем, ни с четвертым. Батчи обрабатываются независимо\n",
        "\n",
        "4. В структуре энкодера данная строка (обычно) удаляется `wei = wei.masked_fill(tril==0, float('-inf'))` - так мы разрешаем первому токену смотреть на последний. То есть все токены видят друг друга.\n",
        "\n",
        "    Но в декодере данная строка присутствует, чтобы не заглядывать в будущее.\n",
        "\n",
        "5. Помимо *self-attention* существует *cross-attention*.\n",
        "\n",
        "    В self-attention *query, key, value* приходят из одного источника `X`. То есть `X` создает *query, key, value*. То есть токены разговаривают друг с другом.\n",
        "\n",
        "    В cross-attention *query* приходят из одного источника `X`, а *key, value* приходят из доп.источника. То есть `X` создает *query*. А *key, value* создаются, например, из энкодера. То есть создается запрос и ищется ответ из другого источника.\n",
        "\n",
        "6. Нужно нормализвать dot.product(query, key). Иначе дисперсия будет большой. Если дисперсия большая, то softmax ломается. Он подстраивается под самое большое значение. И вероятности становятся нулями и одна единица (других вариантов нет), что плохо."
      ],
      "metadata": {
        "id": "dxkblZ9n6sOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##-- пример нормализации весов, чтобы уменьшить дисперсию\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "\n",
        "k = torch.randn(B, T, head_size)\n",
        "q = torch.randn(B, T, head_size)\n",
        "##-- without normalization\n",
        "wei = q @ k.transpose(-2, -1)\n",
        "print(f\"k.var()={k.var():.2f}\")\n",
        "print(f\"q.var()={q.var():.2f}\")\n",
        "print(f\"wei.var()={wei.var():.2f}\")\n",
        "\n",
        "##-- with normalization\n",
        "wei = q @ k.transpose(-2, -1) * head_size**-0.5\n",
        "print(f\"wei.var()={wei.var():.2f}\")"
      ],
      "metadata": {
        "id": "BljSIDrZ_gao",
        "outputId": "080ae996-09bf-4815-b14b-3d27dfb31736",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k.var()=1.09\n",
            "q.var()=1.06\n",
            "wei.var()=18.44\n",
            "wei.var()=1.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##-- пример как ломается softmax\n",
        "test = torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])\n",
        "print(f\"torch.softmax(test, dim=-1): {torch.softmax(test, dim=-1)}\")\n",
        "print(f\"torch.softmax(test*8, dim=-1): {torch.softmax(test*8, dim=-1)}\")\n",
        "print(f\"torch.softmax(test*80, dim=-1): {torch.softmax(test*80, dim=-1)}\")\n",
        "print(f\"torch.softmax(test*800, dim=-1): {torch.softmax(test*800, dim=-1)}\")"
      ],
      "metadata": {
        "id": "mYum5IArA2Mh",
        "outputId": "9bd6608c-407f-4b38-839b-42b19948321d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.softmax(test, dim=-1): tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
            "torch.softmax(test*8, dim=-1): tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n",
            "torch.softmax(test*80, dim=-1): tensor([1.2664e-14, 4.7809e-25, 1.1254e-07, 4.7809e-25, 1.0000e+00])\n",
            "torch.softmax(test*800, dim=-1): tensor([0., 0., 0., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPVQuc8s2Zgm",
        "outputId": "85101669-6cb2-447e-b9bd-05aad8b90c0c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9710, -1.7965,  0.4228, -4.0060,  0.1322, -1.3341, -1.7085,  1.7138],\n",
              "        [ 1.0812, -0.4803,  0.0384,  0.8505,  0.2169,  0.0100, -0.2031,  1.3135],\n",
              "        [-0.5203,  0.8852,  0.2094, -0.4937, -0.0579, -0.1755,  0.0271, -0.7900],\n",
              "        [-0.6459, -0.4687,  0.0900, -0.4316,  0.2010, -0.0377,  0.1445,  1.4498],\n",
              "        [-0.4031,  0.1685, -1.0054, -2.8159, -1.1206, -0.4321,  0.6762, -1.1181],\n",
              "        [-1.3248,  0.3587, -0.2602, -0.2964,  1.4291,  1.5470,  2.0224,  0.1044],\n",
              "        [ 2.1717, -0.3078, -1.0187,  2.2616,  0.3535,  2.7194, -0.1230,  1.0794],\n",
              "        [-0.7118,  0.5290,  1.8042,  1.1229,  1.1120, -1.1012, -0.3576,  0.5112]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S2uIyp50ETE",
        "outputId": "a760f18e-7aaa-46be-c8f2-3ff3a63294fb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.3596, -0.9152],\n",
              "        [ 0.6258,  0.0255],\n",
              "        [ 0.9545,  0.0643],\n",
              "        [ 0.3612,  1.1679],\n",
              "        [-1.3499, -0.5102],\n",
              "        [ 0.2360, -0.2398],\n",
              "        [-0.9211,  1.5433]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aLg5VWfzqbc",
        "outputId": "b695a029-683f-47a5-cdf5-aae976d82bad"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6067,  1.8328,  0.2931,  0.0436,  2.1370, -0.6825, -1.6026, -0.1336,\n",
              "          1.1407,  0.8935, -2.4000, -1.3420, -1.0023, -1.9870, -0.1217, -0.8074],\n",
              "        [ 0.9255, -1.4814,  0.1291, -1.7058,  2.0330, -0.5062, -0.1016, -0.3016,\n",
              "          1.2501, -0.2137, -1.1994, -0.8466, -0.3351,  1.0041,  0.8656,  0.1688],\n",
              "        [-0.2352, -0.2586,  0.0131,  0.8719,  0.9102, -0.1875,  0.7229,  1.4742,\n",
              "         -0.4048, -1.2273,  0.3382,  0.3641, -1.4508, -0.3814,  0.7220,  0.3461],\n",
              "        [ 0.9967,  0.3575,  0.1187, -0.1062,  0.2990,  0.1199, -1.2433,  1.7859,\n",
              "          0.9191,  0.2326,  0.4591,  0.2556, -0.3542,  0.6690,  0.7535, -0.5359],\n",
              "        [-1.0277,  0.5347, -0.7958,  0.4780,  0.1588, -2.3106,  0.3227,  1.5431,\n",
              "         -1.0392, -0.9678, -0.6961,  0.4684,  0.3586, -0.8773,  0.3267, -0.5667],\n",
              "        [ 0.0438, -0.4455, -0.0267,  1.7926, -2.0707, -1.8788, -0.8275,  0.3157,\n",
              "          1.2089,  0.2724,  0.0288,  0.9421, -1.5618,  1.0711,  0.4901, -0.4876],\n",
              "        [ 1.2397, -2.1052,  0.9298, -1.5635,  0.3469, -0.9232,  2.3999, -0.6851,\n",
              "          2.5947,  0.9356, -0.4371, -0.1009,  0.0047, -0.0756, -2.2571,  0.0058],\n",
              "        [-0.0286,  0.4741,  0.3547,  0.3146,  0.0808,  2.6207, -1.2825, -0.4525,\n",
              "         -0.2772, -1.2963, -0.1305, -0.0246, -0.9571,  0.6359,  0.2523,  0.5045]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k[0].T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFzFBFm0zvCT",
        "outputId": "98dec077-fe1e-4970-95a0-af0a31e925ad"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808,  1.3488, -0.6631,  1.6455, -0.8345,  2.4900, -1.6669, -0.3296],\n",
              "        [-0.0700, -0.1396, -0.2513, -0.8030,  0.5978, -1.2237, -1.3651,  0.0080],\n",
              "        [-0.3596,  0.2858,  1.0101,  1.3514, -0.0514,  1.0107, -0.1655,  0.9262],\n",
              "        [-0.9152,  0.9651,  0.1215, -0.2759, -0.0646,  0.5560,  0.9623, -1.8846],\n",
              "        [ 0.6258, -2.0371,  0.1584, -1.5108, -0.4970, -1.5935,  0.0315,  0.1670],\n",
              "        [ 0.0255,  0.4931,  1.1340,  2.1048,  0.4658, -1.2706, -0.7419,  0.4586],\n",
              "        [ 0.9545,  1.4870, -1.1539,  2.7630, -0.2573,  0.6903, -0.2978, -1.7662],\n",
              "        [ 0.0643,  0.5910, -0.2984, -1.7465, -1.0673, -0.1961,  0.0172,  0.5860],\n",
              "        [ 0.3612,  0.1260, -0.5075,  1.4516,  2.0089,  0.3449, -0.1772,  1.7510],\n",
              "        [ 1.1679, -1.5627, -0.9239, -1.5103, -0.5370, -0.3419, -0.1334,  0.2807],\n",
              "        [-1.3499, -1.1601,  0.5467,  0.8212,  0.2228,  0.4759,  0.2940,  0.3110],\n",
              "        [-0.5102, -0.3348, -1.4948, -0.2115,  0.6971, -0.7663,  1.3850, -0.6538],\n",
              "        [ 0.2360,  0.4478, -1.2057,  0.7789, -1.4267, -0.4190,  0.1209, -0.6576],\n",
              "        [-0.2398, -0.8016,  0.5718,  1.5333,  0.9059, -0.4370,  2.5418,  0.3184],\n",
              "        [-0.9211,  1.5236, -0.5974,  1.6097,  0.1446, -1.0012, -0.6405, -0.5496],\n",
              "        [ 1.5433,  2.5086, -0.6937, -0.4032,  0.2280, -0.4094, -1.9740, -1.4649]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5wKhVyRqh-Y",
        "outputId": "a2fd3164-35a3-4f96-f960-79a05a42228f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0660,  0.0865, -0.0022, -0.0979,  0.0494, -0.0847, -0.1617, -0.0495,\n",
              "          0.1284,  0.1332,  0.0091,  0.0597,  0.1579, -0.0382,  0.0418, -0.0894],\n",
              "        [-0.2420,  0.1175, -0.2201, -0.1949,  0.3228,  0.1415, -0.2377,  0.0728,\n",
              "          0.0339,  0.2479,  0.1825, -0.0859,  0.2657, -0.0599, -0.1402, -0.2509],\n",
              "        [ 0.0238,  0.1610, -0.0689, -0.2005,  0.1682, -0.0809, -0.3061, -0.0503,\n",
              "          0.1969,  0.2677,  0.0678,  0.0612,  0.3090, -0.0734,  0.0190, -0.2049],\n",
              "        [ 0.2719,  0.2343,  0.0551, -0.2476,  0.0619, -0.3013, -0.4325, -0.1734,\n",
              "          0.3870,  0.3417, -0.0230,  0.2085,  0.4131, -0.1010,  0.1686, -0.2056],\n",
              "        [ 0.1616,  0.1602,  0.0217, -0.1739,  0.0611, -0.1873, -0.2971, -0.1083,\n",
              "          0.2543,  0.2386, -0.0032,  0.1304,  0.2863, -0.0697,  0.1009, -0.1501],\n",
              "        [-0.6233, -0.2353, -0.2847,  0.1831,  0.2080,  0.5735,  0.4151,  0.3220,\n",
              "         -0.5368, -0.2723,  0.2028, -0.3858, -0.3607,  0.0929, -0.3774,  0.0697],\n",
              "        [ 0.1164,  0.0891,  0.0295, -0.0917,  0.0135, -0.1246, -0.1637, -0.0714,\n",
              "          0.1526,  0.1272, -0.0154,  0.0858,  0.1550, -0.0381,  0.0718, -0.0731],\n",
              "        [-0.3887, -0.2972, -0.0986,  0.3058, -0.0446,  0.4161,  0.5462,  0.2385,\n",
              "         -0.5094, -0.4245,  0.0517, -0.2866, -0.5172,  0.1270, -0.2399,  0.2437]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title bigram_v3\n",
        "bigram_v3 = \\\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "##-- hyperparameters\n",
        "batch_size = 32 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
        "block_size = 8 ##-- максимальная длина предложения (в нашем случае, количество символов)\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 32 ##-- размер эмбединга\n",
        "##------------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# here all the unique character that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "##-- create mapping from characters to integers\n",
        "stoi = { ch: i for i, ch in enumerate(chars) }\n",
        "atoi = { i: ch for i, ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([atoi[i] for i in l])\n",
        "\n",
        "##-- Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "##-- data loading\n",
        "def get_batch(split: str='train'):\n",
        "    '''\n",
        "    generate a small batch of data of inputs x and targets y\n",
        "\n",
        "    split: str: train or test\n",
        "    '''\n",
        "    data = train_data if split=='train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size, )) ##-- random idx\n",
        "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return (x, y)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    ''' one head of self-attention '''\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x) # (B, T, C)\n",
        "        k = self.key(x) # (B, T, C)\n",
        "        ##-- compute attention score 'affinities' (взаимоотношения между токенами)\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5 # (B, T, C) @ (B, C, T) -->> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        # perform the weighted aggregation of the value\n",
        "        v = self.value(x) # (B, T, C)\n",
        "        out = wei @ v  # (B, T, T) @ (B, T, C) -->> (B, T, C)\n",
        "        return out\n",
        "\n",
        "\n",
        "##-- super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ##-- each token directly read oof the logits for the next token from a lookip table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) ##-- берем эмбединг токена (кодируем токен)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd) ##-- кодируем позицию токена\n",
        "        self.sa_head = Head(n_embd) ##-- one head of self-attention (B, T, C)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size) ##-- linear_model head\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        ##-- idx and targets are both (B, T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B, T, C) #-- (4, 8, 32), (batch_size, block_size, emb_size)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C) (8, 32) ##-- кодируем позицию токена\n",
        "        x = tok_emb + pos_emb ##-- (B, T, C) эмбединг токена и его позиции\n",
        "        x = self.sa_head(x) ##-- apple one head of self-attention (B, T, C)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size) #-- (4, 8, 65), (batch_size, block_size, vocab_size)\n",
        "        # print(logits.shape) # (4, 8, 65)\n",
        "        # print(targets.shape) # (4, 8)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            ##-- из батча размером 4 предложения переводим в одну строку (то есть четыре предложения в одно)\n",
        "            logits = logits.view(B*T, C)\n",
        "            ##-- второй вариант, таргеты в таком случае тоже не менять\n",
        "            # logits = torch.permute(logits, (0, 2, 1))\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens: int=100):\n",
        "        ##-- idx is the (B, T) array of the indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            ##-- crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            ##-- get the predictions\n",
        "            logits, _ = self(idx_cond)\n",
        "            ##-- focus only on the last time step (последнюю букву)\n",
        "            # print(f\"logits_before ={logits}, {logits.shape}\")\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # print(f\"logits_after ={logits}, {logits.shape}\")\n",
        "            ##-- softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # print(probs)\n",
        "            ##-- sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # print(idx_next)\n",
        "            ##-- append sampled idx to the running sample\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "\n",
        "##-- pytorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "\n",
        "##-- fit\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    ##-- sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    ##-- evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "##-- generate the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bDA9lGUw1849"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILENAME = 'bigram_v3.py'\n",
        "save(bigram_v3, FILENAME)"
      ],
      "metadata": {
        "id": "tq7QOCuW175V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86358069-9f20-42a4-9b9b-adbf97e64d73"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved file at: /content/bigram_v3.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! diff bigram_v2.py bigram_v3.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i_M5KSVSTNv",
        "outputId": "b3597ec2-0ccb-4b48-d883-eea60b11b3a7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2d1\n",
            "< \n",
            "8c7\n",
            "< batch_size = 4 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
            "---\n",
            "> batch_size = 32 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
            "10,12c9,11\n",
            "< max_iters = 300\n",
            "< eval_interval = 300\n",
            "< learning_rate = 1e-2\n",
            "---\n",
            "> max_iters = 5000\n",
            "> eval_interval = 500\n",
            "> learning_rate = 1e-3\n",
            "67a67,90\n",
            "> class Head(nn.Module):\n",
            ">     ''' one head of self-attention '''\n",
            "> \n",
            ">     def __init__(self, head_size):\n",
            ">         super().__init__()\n",
            ">         self.query = nn.Linear(n_embd, head_size, bias=False)\n",
            ">         self.key = nn.Linear(n_embd, head_size, bias=False)\n",
            ">         self.value = nn.Linear(n_embd, head_size, bias=False)\n",
            ">         self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
            "> \n",
            ">     def forward(self, x):\n",
            ">         B, T, C = x.shape\n",
            ">         q = self.query(x) # (B, T, C)\n",
            ">         k = self.key(x) # (B, T, C)\n",
            ">         ##-- compute attention score 'affinities' (взаимоотношения между токенами)\n",
            ">         wei = q @ k.transpose(-2, -1) * C**-0.5 # (B, T, C) @ (B, C, T) -->> (B, T, T)\n",
            ">         wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # (B, T, T)\n",
            ">         wei = F.softmax(wei, dim=-1)\n",
            ">         # perform the weighted aggregation of the value\n",
            ">         v = self.value(x) # (B, T, C)\n",
            ">         out = wei @ v  # (B, T, T) @ (B, T, C) -->> (B, T, C)\n",
            ">         return out\n",
            "> \n",
            "> \n",
            "74a98\n",
            ">         self.sa_head = Head(n_embd) ##-- one head of self-attention (B, T, C)\n",
            "83a108\n",
            ">         x = self.sa_head(x) ##-- apple one head of self-attention (B, T, C)\n",
            "102a128,129\n",
            ">             ##-- crop idx to the last block_size tokens\n",
            ">             idx_cond = idx[:, -block_size:]\n",
            "104c131\n",
            "<             logits, _ = self(idx)\n",
            "---\n",
            ">             logits, _ = self(idx_cond)\n",
            "106c133\n",
            "<             print(f\"logits_before ={logits}, {logits.shape}\")\n",
            "---\n",
            ">             # print(f\"logits_before ={logits}, {logits.shape}\")\n",
            "108c135\n",
            "<             print(f\"logits_after ={logits}, {logits.shape}\")\n",
            "---\n",
            ">             # print(f\"logits_after ={logits}, {logits.shape}\")\n",
            "111c138\n",
            "<             print(probs)\n",
            "---\n",
            ">             # print(probs)\n",
            "114c141\n",
            "<             print(idx_next)\n",
            "---\n",
            ">             # print(idx_next)\n",
            "136c163\n",
            "<     logits, loss = model(xb, yb)\n",
            "---\n",
            ">     logits, loss = m(xb, yb)\n",
            "141c168\n",
            "< ##-- generate from the model\n",
            "---\n",
            "> ##-- generate the model\n",
            "143c170\n",
            "< print(decode(m.generate(context, max_new_tokens=10)[0].tolist()))\n",
            "---\n",
            "> print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "! python bigram_v3.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heUtjii_S4bi",
        "outputId": "94adee09-b7d8-4bf9-8e1f-0ee32ab68496"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.1990, val loss 4.2031\n",
            "step 500: train loss 2.6944, val loss 2.7091\n",
            "step 1000: train loss 2.5214, val loss 2.5316\n",
            "step 1500: train loss 2.4762, val loss 2.4833\n",
            "step 2000: train loss 2.4408, val loss 2.4517\n",
            "step 2500: train loss 2.4279, val loss 2.4433\n",
            "step 3000: train loss 2.4126, val loss 2.4314\n",
            "step 3500: train loss 2.3950, val loss 2.4190\n",
            "step 4000: train loss 2.4033, val loss 2.3961\n",
            "step 4500: train loss 2.3976, val loss 2.4041\n",
            "\n",
            "Whent iknt,\n",
            "Thowi, ht son, bth\n",
            "\n",
            "Hiset bobe ale.\n",
            "S:\n",
            "O-' st dalilanss: rant he us he, vet?\n",
            "Wed las ate awice my.\n",
            "\n",
            "HDET:\n",
            "ANGo oug\n",
            "Yowns, tof isth bot mil ndill, aes iree sen cie lat Herid ovets, and Win ngarigoerabous lelind peal.\n",
            "-hule onchiry ptugr aiss hew ye wllinde norod atelaves\n",
            "Momy yowod mothake ont-wou whrt eiiby we ati fourive wee, ired thoouso er; thu the banterupt f so;\n",
            "ARID Wam:\n",
            "ENGCI inleront ffaf Pre?\n",
            "\n",
            "Whiom.\n",
            "\n",
            "He-\n",
            "LIERCKENIGUICI\n",
            "Sadsal aces ard thinin cour ay aney Iry ts I fr af ve y\n",
            "CPU times: user 167 ms, sys: 33.5 ms, total: 200 ms\n",
            "Wall time: 29.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MultiHead attention\n",
        "\n",
        "multihead attention - это просто параллельное выполнение нескольких видов attention и объединение (конкатенация) результатов.\n",
        "\n",
        "Параллельный запуск нескольких голов помогает тем, что каждая голова собирает свою независимую информацию. Потом они объединяются и получают неплохой результат"
      ],
      "metadata": {
        "id": "oI29ac5M2a6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title bigram_v4.py\n",
        "\n",
        "bigram_v4 = \\\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "##-- hyperparameters\n",
        "batch_size = 32 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
        "block_size = 8 ##-- максимальная длина предложения (в нашем случае, количество символов)\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 32 ##-- размер эмбединга\n",
        "##------------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# here all the unique character that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "##-- create mapping from characters to integers\n",
        "stoi = { ch: i for i, ch in enumerate(chars) }\n",
        "atoi = { i: ch for i, ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([atoi[i] for i in l])\n",
        "\n",
        "##-- Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "##-- data loading\n",
        "def get_batch(split: str='train'):\n",
        "    '''\n",
        "    generate a small batch of data of inputs x and targets y\n",
        "\n",
        "    split: str: train or test\n",
        "    '''\n",
        "    data = train_data if split=='train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size, )) ##-- random idx\n",
        "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return (x, y)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    ''' one head of self-attention '''\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x) # (B, T, C)\n",
        "        k = self.key(x) # (B, T, C)\n",
        "        ##-- compute attention score 'affinities' (взаимоотношения между токенами)\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5 # (B, T, C) @ (B, C, T) -->> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        # perform the weighted aggregation of the value\n",
        "        v = self.value(x) # (B, T, C)\n",
        "        out = wei @ v  # (B, T, T) @ (B, T, C) -->> (B, T, C)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    ''' multiple heads of self-attention in parallel '''\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([h(x) for h in self.heads], dim=-1) ##-- объединение по каналам\n",
        "\n",
        "\n",
        "##-- super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ##-- each token directly read oof the logits for the next token from a lookip table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) ##-- берем эмбединг токена (кодируем токен)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd) ##-- кодируем позицию токена\n",
        "        self.sa_heads = MultiHeadAttention(4, n_embd // 4) ##-- (B, T, C) 4 головы, каждая размером 8 (то есть на выходе эмбединг = 32)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size) ##-- linear_model head\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        ##-- idx and targets are both (B, T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B, T, C) #-- (4, 8, 32), (batch_size, block_size, emb_size)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C) (8, 32) ##-- кодируем позицию токена\n",
        "        x = tok_emb + pos_emb ##-- (B, T, C) эмбединг токена и его позиции\n",
        "        x = self.sa_heads(x) ##-- apple one head of self-attention (B, T, C)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size) #-- (4, 8, 65), (batch_size, block_size, vocab_size)\n",
        "        # print(logits.shape) # (4, 8, 65)\n",
        "        # print(targets.shape) # (4, 8)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            ##-- из батча размером 4 предложения переводим в одну строку (то есть четыре предложения в одно)\n",
        "            logits = logits.view(B*T, C)\n",
        "            ##-- второй вариант, таргеты в таком случае тоже не менять\n",
        "            # logits = torch.permute(logits, (0, 2, 1))\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens: int=100):\n",
        "        ##-- idx is the (B, T) array of the indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            ##-- crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            ##-- get the predictions\n",
        "            logits, _ = self(idx_cond)\n",
        "            ##-- focus only on the last time step (последнюю букву)\n",
        "            # print(f\"logits_before ={logits}, {logits.shape}\")\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # print(f\"logits_after ={logits}, {logits.shape}\")\n",
        "            ##-- softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # print(probs)\n",
        "            ##-- sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # print(idx_next)\n",
        "            ##-- append sampled idx to the running sample\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "\n",
        "##-- pytorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "\n",
        "##-- fit\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    ##-- sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    ##-- evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "##-- generate the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ypFutttKvPeD",
        "cellView": "form"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILENAME = 'bigram_v4.py'\n",
        "save(bigram_v4, FILENAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKwTwesUSZlM",
        "outputId": "e35c19f9-9db4-4a9d-b992-b58e0fc756b2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved file at: /content/bigram_v4.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! diff bigram_v3.py bigram_v4.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um8RiAsvSeJt",
        "outputId": "4e3c2122-21a0-4f27-9e03-c99969e128ad"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90a91,101\n",
            "> class MultiHeadAttention(nn.Module):\n",
            ">     ''' multiple heads of self-attention in parallel '''\n",
            "> \n",
            ">     def __init__(self, num_heads, head_size):\n",
            ">         super().__init__()\n",
            ">         self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
            "> \n",
            ">     def forward(self, x):\n",
            ">         return torch.cat([h(x) for h in self.heads], dim=-1) ##-- объединение по каналам\n",
            "> \n",
            "> \n",
            "98c109\n",
            "<         self.sa_head = Head(n_embd) ##-- one head of self-attention (B, T, C)\n",
            "---\n",
            ">         self.sa_heads = MultiHeadAttention(4, n_embd // 4) ##-- (B, T, C) 4 головы, каждая размером 8 (то есть на выходе эмбединг = 32)\n",
            "108c119\n",
            "<         x = self.sa_head(x) ##-- apple one head of self-attention (B, T, C)\n",
            "---\n",
            ">         x = self.sa_heads(x) ##-- apple one head of self-attention (B, T, C)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "! python bigram_v4.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hOe8Ay2S3B7",
        "outputId": "299b3780-633c-43d8-e597-1d003ffdd408"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.2229, val loss 4.2220\n",
            "step 500: train loss 2.6454, val loss 2.6623\n",
            "step 1000: train loss 2.4841, val loss 2.4949\n",
            "step 1500: train loss 2.4184, val loss 2.4251\n",
            "step 2000: train loss 2.3641, val loss 2.3774\n",
            "step 2500: train loss 2.3359, val loss 2.3473\n",
            "step 3000: train loss 2.3119, val loss 2.3272\n",
            "step 3500: train loss 2.2861, val loss 2.3109\n",
            "step 4000: train loss 2.2852, val loss 2.2783\n",
            "step 4500: train loss 2.2679, val loss 2.2789\n",
            "\n",
            "Whent if tridcowd, whis by bee\n",
            "\n",
            "Hiret bobe toe.\n",
            "Sagrtand wealleauss:\n",
            "Waith fuulqure vet?\n",
            "W dilth ate arcce my.\n",
            "\n",
            "ODET:\n",
            "An oroug\n",
            "Yowns, tof is heice mil; dill, aeg isee sen cin lat Helilrov the and Wing.\n",
            "\n",
            "Don you sesel lind peall lish wonchiry prug; aiss hiw yevellinge nordoperelaves\n",
            "Mom\n",
            "Is wod mothake onWinso whroCeriby wey thourstis The shiend to-o--\n",
            "And; the the banterthirf son; igr to whit thy ale of,\n",
            "Toff Prive my of.\n",
            "\n",
            "HINNGIES:\n",
            "Wied is:\n",
            "Sadsal aces ghe thiuin couk ay andy Iur to I frouf vouc\n",
            "CPU times: user 256 ms, sys: 50.5 ms, total: 307 ms\n",
            "Wall time: 50.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feed Forward Network\n",
        "\n",
        "Это можно представить как \"обдумывание\".\n",
        "\n",
        "Multihead attention позволяла токенам \"пообщаться\" друг с другом, то есть узнать друг друга. А feedforward как бы дает паузу, чтобы обдумать то, что они узнали друг о друге."
      ],
      "metadata": {
        "id": "Wa0B74d36aCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title bigram_v5\n",
        "bigram_v5 = \\\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "##-- hyperparameters\n",
        "batch_size = 32 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
        "block_size = 8 ##-- максимальная длина предложения (в нашем случае, количество символов)\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 32 ##-- размер эмбединга\n",
        "##------------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# here all the unique character that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "##-- create mapping from characters to integers\n",
        "stoi = { ch: i for i, ch in enumerate(chars) }\n",
        "atoi = { i: ch for i, ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([atoi[i] for i in l])\n",
        "\n",
        "##-- Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "##-- data loading\n",
        "def get_batch(split: str='train'):\n",
        "    '''\n",
        "    generate a small batch of data of inputs x and targets y\n",
        "\n",
        "    split: str: train or test\n",
        "    '''\n",
        "    data = train_data if split=='train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size, )) ##-- random idx\n",
        "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return (x, y)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    ''' one head of self-attention '''\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x) # (B, T, C)\n",
        "        k = self.key(x) # (B, T, C)\n",
        "        ##-- compute attention score 'affinities' (взаимоотношения между токенами)\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5 # (B, T, C) @ (B, C, T) -->> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        # perform the weighted aggregation of the value\n",
        "        v = self.value(x) # (B, T, C)\n",
        "        out = wei @ v  # (B, T, T) @ (B, T, C) -->> (B, T, C)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    ''' multiple heads of self-attention in parallel '''\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([h(x) for h in self.heads], dim=-1) ##-- объединение по каналам\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    ''' a simple linear layer followed by a non-linearity '''\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, n_embd),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "##-- super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ##-- each token directly read oof the logits for the next token from a lookip table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) ##-- берем эмбединг токена (кодируем токен)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd) ##-- кодируем позицию токена\n",
        "        self.sa_heads = MultiHeadAttention(4, n_embd // 4) ##-- (B, T, C) 4 головы, каждая размером 8 (то есть на выходе эмбединг = 32)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size) ##-- linear_model head\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        ##-- idx and targets are both (B, T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B, T, C) #-- (4, 8, 32), (batch_size, block_size, emb_size)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C) (8, 32) ##-- кодируем позицию токена\n",
        "        x = tok_emb + pos_emb ##-- (B, T, C) эмбединг токена и его позиции\n",
        "        x = self.sa_heads(x) ##-- apply 4 heads of self-attention (B, T, C)\n",
        "        x = self.ffwd(x) ##-- (B, T, C)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size) #-- (4, 8, 65), (batch_size, block_size, vocab_size)\n",
        "        # print(logits.shape) # (4, 8, 65)\n",
        "        # print(targets.shape) # (4, 8)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            ##-- из батча размером 4 предложения переводим в одну строку (то есть четыре предложения в одно)\n",
        "            logits = logits.view(B*T, C)\n",
        "            ##-- второй вариант, таргеты в таком случае тоже не менять\n",
        "            # logits = torch.permute(logits, (0, 2, 1))\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens: int=100):\n",
        "        ##-- idx is the (B, T) array of the indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            ##-- crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            ##-- get the predictions\n",
        "            logits, _ = self(idx_cond)\n",
        "            ##-- focus only on the last time step (последнюю букву)\n",
        "            # print(f\"logits_before ={logits}, {logits.shape}\")\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # print(f\"logits_after ={logits}, {logits.shape}\")\n",
        "            ##-- softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # print(probs)\n",
        "            ##-- sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # print(idx_next)\n",
        "            ##-- append sampled idx to the running sample\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "\n",
        "##-- pytorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "\n",
        "##-- fit\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    ##-- sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    ##-- evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "##-- generate the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "a6jyrOHQ6fDh",
        "cellView": "form"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILENAME = 'bigram_v5.py'\n",
        "save(bigram_v5, FILENAME)"
      ],
      "metadata": {
        "id": "20gsVDJW8K3q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0401653-875e-47c4-b9b3-1beefcfd6a87"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved file at: /content/bigram_v5.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! diff bigram_v4.py bigram_v5.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncsg7sCfSmcO",
        "outputId": "da2dd473-ace6-4165-a916-20747e639e83"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101a102,115\n",
            "> class FeedForward(nn.Module):\n",
            ">     ''' a simple linear layer followed by a non-linearity '''\n",
            "> \n",
            ">     def __init__(self, n_embd):\n",
            ">         super().__init__()\n",
            ">         self.net = nn.Sequential(\n",
            ">             nn.Linear(n_embd, n_embd),\n",
            ">             nn.ReLU()\n",
            ">         )\n",
            "> \n",
            ">     def forward(self, x):\n",
            ">         return self.net(x)\n",
            "> \n",
            "> \n",
            "109a124\n",
            ">         self.ffwd = FeedForward(n_embd)\n",
            "119c134,135\n",
            "<         x = self.sa_heads(x) ##-- apple one head of self-attention (B, T, C)\n",
            "---\n",
            ">         x = self.sa_heads(x) ##-- apply 4 heads of self-attention (B, T, C)\n",
            ">         x = self.ffwd(x) ##-- (B, T, C)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "! python bigram_v5.py"
      ],
      "metadata": {
        "id": "FXY6wnjK8UoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d32c7dd5-b015-4bea-eba8-fbcb06f1a65a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.1994, val loss 4.1993\n",
            "step 500: train loss 2.5829, val loss 2.5937\n",
            "step 1000: train loss 2.4608, val loss 2.4632\n",
            "step 1500: train loss 2.3987, val loss 2.3980\n",
            "step 2000: train loss 2.3334, val loss 2.3507\n",
            "step 2500: train loss 2.3051, val loss 2.3284\n",
            "step 3000: train loss 2.2896, val loss 2.3052\n",
            "step 3500: train loss 2.2568, val loss 2.2849\n",
            "step 4000: train loss 2.2486, val loss 2.2559\n",
            "step 4500: train loss 2.2336, val loss 2.2478\n",
            "\n",
            "Will thy tridcow and is and the a thom obe to tavegr-and thalllands:\n",
            "Waith foulquethe thar dill\n",
            "Haten wice my.\n",
            "\n",
            "Hnd acut onoth\n",
            "Yowthertof is he cove the ill, aed iree sen cin lat Hetilkev the and to por:\n",
            "Wilerans!\n",
            " lelind teall thull cechir sother aiss hiwty.\n",
            "Hur nie norfore tigtle\n",
            "Mom\n",
            "Gll, demethake on indo whre piiby, to thour rive ceeshime st so mowe-xore\n",
            "To k danteruft for tre\n",
            "QULETE:\n",
            "\n",
            "Enge inled ath, af Pried my ome.\n",
            "He-Nuck!\n",
            "\n",
            "Wind is:\n",
            "Sadsal the E'd st hoth cour aar tey Ire to cof my cardy\n",
            "CPU times: user 274 ms, sys: 52.5 ms, total: 327 ms\n",
            "Wall time: 53.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Block (Multihead attention + Feedforward several times)\n",
        "\n",
        "Добавление только blocks только ухудшает качество модели, так как модель становится глубокой, то происходит затухание градиентов. Чтобы это исправить, нужно добавить residual connection\n",
        "\n"
      ],
      "metadata": {
        "id": "ETZ3IwaM72hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title bigram_v6\n",
        "bigram_v6 = \\\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "##-- hyperparameters\n",
        "batch_size = 32 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
        "block_size = 8 ##-- максимальная длина предложения (в нашем случае, количество символов)\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 32 ##-- размер эмбединга\n",
        "##------------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# here all the unique character that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "##-- create mapping from characters to integers\n",
        "stoi = { ch: i for i, ch in enumerate(chars) }\n",
        "atoi = { i: ch for i, ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([atoi[i] for i in l])\n",
        "\n",
        "##-- Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "##-- data loading\n",
        "def get_batch(split: str='train'):\n",
        "    '''\n",
        "    generate a small batch of data of inputs x and targets y\n",
        "\n",
        "    split: str: train or test\n",
        "    '''\n",
        "    data = train_data if split=='train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size, )) ##-- random idx\n",
        "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return (x, y)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    ''' one head of self-attention '''\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x) # (B, T, C)\n",
        "        k = self.key(x) # (B, T, C)\n",
        "        ##-- compute attention score 'affinities' (взаимоотношения между токенами)\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5 # (B, T, C) @ (B, C, T) -->> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        # perform the weighted aggregation of the value\n",
        "        v = self.value(x) # (B, T, C)\n",
        "        out = wei @ v  # (B, T, T) @ (B, T, C) -->> (B, T, C)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    ''' multiple heads of self-attention in parallel '''\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([h(x) for h in self.heads], dim=-1) ##-- объединение по каналам\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    ''' a simple linear layer followed by a non-linearity '''\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, n_embd),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    ''' Transformer block: communication followed by computation '''\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.sa(x)\n",
        "        x = self.ffwd(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "##-- super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ##-- each token directly read oof the logits for the next token from a lookip table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) ##-- берем эмбединг токена (кодируем токен)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd) ##-- кодируем позицию токена\n",
        "        self.blocks = nn.Sequential(\n",
        "            Block(n_embd, n_head=4),\n",
        "            Block(n_embd, n_head=4),\n",
        "            Block(n_embd, n_head=4),\n",
        "        ) ##-- MultiheadAttention -> FFN 3 times\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size) ##-- linear_model head\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        ##-- idx and targets are both (B, T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B, T, C) #-- (4, 8, 32), (batch_size, block_size, emb_size)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C) (8, 32) ##-- кодируем позицию токена\n",
        "        x = tok_emb + pos_emb ##-- (B, T, C) эмбединг токена и его позиции\n",
        "        x = self.blocks(x) ##-- apply 4 heads of self-attention (B, T, C)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size) #-- (4, 8, 65), (batch_size, block_size, vocab_size)\n",
        "        # print(logits.shape) # (4, 8, 65)\n",
        "        # print(targets.shape) # (4, 8)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            ##-- из батча размером 4 предложения переводим в одну строку (то есть четыре предложения в одно)\n",
        "            logits = logits.view(B*T, C)\n",
        "            ##-- второй вариант, таргеты в таком случае тоже не менять\n",
        "            # logits = torch.permute(logits, (0, 2, 1))\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens: int=100):\n",
        "        ##-- idx is the (B, T) array of the indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            ##-- crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            ##-- get the predictions\n",
        "            logits, _ = self(idx_cond)\n",
        "            ##-- focus only on the last time step (последнюю букву)\n",
        "            # print(f\"logits_before ={logits}, {logits.shape}\")\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # print(f\"logits_after ={logits}, {logits.shape}\")\n",
        "            ##-- softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # print(probs)\n",
        "            ##-- sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # print(idx_next)\n",
        "            ##-- append sampled idx to the running sample\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "\n",
        "##-- pytorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "\n",
        "##-- fit\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    ##-- sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    ##-- evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "##-- generate the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "onJEcWKD72cn"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILENAME = 'bigram_v6.py'\n",
        "save(bigram_v6, FILENAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjS70daN_Vb1",
        "outputId": "feecc655-c93e-4a8e-ffad-87eab5b3235c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved file at: /content/bigram_v6.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! diff bigram_v5.py bigram_v6.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBJmZzfeFPWC",
        "outputId": "8190b13c-3aaf-4b25-c0c0-8cfb9465af2b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1a2\n",
            "> \n",
            "115a117,131\n",
            "> class Block(nn.Module):\n",
            ">     ''' Transformer block: communication followed by computation '''\n",
            "> \n",
            ">     def __init__(self, n_embd, n_head):\n",
            ">         super().__init__()\n",
            ">         head_size = n_embd // n_head\n",
            ">         self.sa = MultiHeadAttention(n_head, head_size)\n",
            ">         self.ffwd = FeedForward(n_embd)\n",
            ">     \n",
            ">     def forward(self, x):\n",
            ">         x = self.sa(x)\n",
            ">         x = self.ffwd(x)\n",
            ">         return x\n",
            "> \n",
            "> \n",
            "123,124c139,143\n",
            "<         self.sa_heads = MultiHeadAttention(4, n_embd // 4) ##-- (B, T, C) 4 головы, каждая размером 8 (то есть на выходе эмбединг = 32)\n",
            "<         self.ffwd = FeedForward(n_embd)\n",
            "---\n",
            ">         self.blocks = nn.Sequential(\n",
            ">             Block(n_embd, n_head=4),\n",
            ">             Block(n_embd, n_head=4),\n",
            ">             Block(n_embd, n_head=4),\n",
            ">         ) ##-- MultiheadAttention -> FFN 3 times\n",
            "134,135c153\n",
            "<         x = self.sa_heads(x) ##-- apply 4 heads of self-attention (B, T, C)\n",
            "<         x = self.ffwd(x) ##-- (B, T, C)\n",
            "---\n",
            ">         x = self.blocks(x) ##-- apply 4 heads of self-attention (B, T, C)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "! python bigram_v6.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1XUwmc080sL",
        "outputId": "3f181af6-ee46-43f9-b462-8137ac3e07b2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.2116, val loss 4.2078\n",
            "step 500: train loss 3.1064, val loss 3.1091\n",
            "step 1000: train loss 2.8667, val loss 2.8511\n",
            "step 1500: train loss 2.6722, val loss 2.6536\n",
            "step 2000: train loss 2.5680, val loss 2.5777\n",
            "step 2500: train loss 2.5047, val loss 2.4935\n",
            "step 3000: train loss 2.4558, val loss 2.4622\n",
            "step 3500: train loss 2.4198, val loss 2.4349\n",
            "step 4000: train loss 2.4070, val loss 2.3855\n",
            "step 4500: train loss 2.3726, val loss 2.3828\n",
            "\n",
            "And thef bridc wilen is by bee\n",
            "baceer bobe dontaSthr-' my dalata\n",
            "he ar hapae uwqore to barddt\n",
            "ASoates wice my thans'n on onom waoths\n",
            "Mtof is heing mil nowl boues iree sen cin lat Het drovets, and to pomant.\n",
            "\n",
            "Wabs!\n",
            "Al lind me litens;\n",
            "Honc my sothpe anss hew younls mas korfd atelg dowhom\n",
            "thaked mothakleo Wind to do eiibas to thours\n",
            "Wor cens ired to-Lcol erxore\n",
            "To kad nonruft fis to irk to she wrey aleront to fim.\n",
            "\n",
            "CORISos.\n",
            "\n",
            "HKINLIES:\n",
            "Toy dis:\n",
            "Sadsal thes gef thiuin couk aar tey Ire to chan you! hi\n",
            "CPU times: user 530 ms, sys: 107 ms, total: 637 ms\n",
            "Wall time: 1min 53s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Residual connection\n",
        "\n",
        "Residual connection (соединение остаточной связи) - это механизм, который используется в нейронных сетях для передачи информации из одного слоя в другой, обеспечивая более эффективное обучение. Он заключается в том, что на каждом слое данных добавляется остаточное соединение, которое передает информацию от входа к выходу слоя, минуя блоки обработки данных. Это позволяет улучшить качество обучения и снизить вероятность переобучения модели.\n",
        "\n",
        "residual connection сохраняет и передает информацию, которая может быть полезной для более поздних этапов нейронной сети. Это позволяет улучшить качество предсказаний и ускорить обучение сети."
      ],
      "metadata": {
        "id": "q0Ci8icA_9sT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title bigram_v7\n",
        "bigram_v7 = \\\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "##-- hyperparameters\n",
        "batch_size = 32 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
        "block_size = 8 ##-- максимальная длина предложения (в нашем случае, количество символов)\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 32 ##-- размер эмбединга\n",
        "##------------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# here all the unique character that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "##-- create mapping from characters to integers\n",
        "stoi = { ch: i for i, ch in enumerate(chars) }\n",
        "atoi = { i: ch for i, ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([atoi[i] for i in l])\n",
        "\n",
        "##-- Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "##-- data loading\n",
        "def get_batch(split: str='train'):\n",
        "    '''\n",
        "    generate a small batch of data of inputs x and targets y\n",
        "\n",
        "    split: str: train or test\n",
        "    '''\n",
        "    data = train_data if split=='train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size, )) ##-- random idx\n",
        "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return (x, y)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    ''' one head of self-attention '''\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x) # (B, T, C)\n",
        "        k = self.key(x) # (B, T, C)\n",
        "        ##-- compute attention score 'affinities' (взаимоотношения между токенами)\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5 # (B, T, C) @ (B, C, T) -->> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        # perform the weighted aggregation of the value\n",
        "        v = self.value(x) # (B, T, C)\n",
        "        out = wei @ v  # (B, T, T) @ (B, T, C) -->> (B, T, C)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    ''' multiple heads of self-attention in parallel '''\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd) ##-- for residual connection\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) ##-- объединение по каналам\n",
        "        out = self.proj(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    ''' a simple linear layer followed by a non-linearity '''\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd) ##-- for residual connection\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    ''' Transformer block: communication followed by computation '''\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(x) ##-- add residual connection\n",
        "        x = x + self.ffwd(x) ##-- add residual connection\n",
        "        return x\n",
        "\n",
        "\n",
        "##-- super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ##-- each token directly read oof the logits for the next token from a lookip table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) ##-- берем эмбединг токена (кодируем токен)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd) ##-- кодируем позицию токена\n",
        "        self.blocks = nn.Sequential(\n",
        "            Block(n_embd, n_head=4),\n",
        "            Block(n_embd, n_head=4),\n",
        "            Block(n_embd, n_head=4),\n",
        "        ) ##-- MultiheadAttention -> FFN 3 times\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size) ##-- linear_model head\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        ##-- idx and targets are both (B, T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B, T, C) #-- (4, 8, 32), (batch_size, block_size, emb_size)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C) (8, 32) ##-- кодируем позицию токена\n",
        "        x = tok_emb + pos_emb ##-- (B, T, C) эмбединг токена и его позиции\n",
        "        x = self.blocks(x) ##-- apply 4 heads of self-attention (B, T, C)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size) #-- (4, 8, 65), (batch_size, block_size, vocab_size)\n",
        "        # print(logits.shape) # (4, 8, 65)\n",
        "        # print(targets.shape) # (4, 8)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            ##-- из батча размером 4 предложения переводим в одну строку (то есть четыре предложения в одно)\n",
        "            logits = logits.view(B*T, C)\n",
        "            ##-- второй вариант, таргеты в таком случае тоже не менять\n",
        "            # logits = torch.permute(logits, (0, 2, 1))\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens: int=100):\n",
        "        ##-- idx is the (B, T) array of the indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            ##-- crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            ##-- get the predictions\n",
        "            logits, _ = self(idx_cond)\n",
        "            ##-- focus only on the last time step (последнюю букву)\n",
        "            # print(f\"logits_before ={logits}, {logits.shape}\")\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # print(f\"logits_after ={logits}, {logits.shape}\")\n",
        "            ##-- softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # print(probs)\n",
        "            ##-- sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # print(idx_next)\n",
        "            ##-- append sampled idx to the running sample\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "\n",
        "##-- pytorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "\n",
        "##-- fit\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    ##-- sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    ##-- evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "##-- generate the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6DOrV6wE_9VF",
        "cellView": "form"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILENAME = 'bigram_v7.py'\n",
        "save(bigram_v7, FILENAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXm5HvWyHNle",
        "outputId": "a282152e-b749-4626-a7a5-c1ecb51a5c09"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved file at: /content/bigram_v7.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! diff bigram_v6.py bigram_v7.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aLZyDVo7WoR",
        "outputId": "1dffcd34-4000-4c62-daeb-4790ff7ac0c5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2a3\n",
            "> \n",
            "97a99\n",
            ">         self.proj = nn.Linear(n_embd, n_embd) ##-- for residual connection\n",
            "100c102,104\n",
            "<         return torch.cat([h(x) for h in self.heads], dim=-1) ##-- объединение по каналам\n",
            "---\n",
            ">         out = torch.cat([h(x) for h in self.heads], dim=-1) ##-- объединение по каналам\n",
            ">         out = self.proj(out)\n",
            ">         return out\n",
            "109,110c113,115\n",
            "<             nn.Linear(n_embd, n_embd),\n",
            "<             nn.ReLU()\n",
            "---\n",
            ">             nn.Linear(n_embd, 4 * n_embd),\n",
            ">             nn.ReLU(),\n",
            ">             nn.Linear(4 * n_embd, n_embd) ##-- for residual connection\n",
            "127,128c132,133\n",
            "<         x = self.sa(x)\n",
            "<         x = self.ffwd(x)\n",
            "---\n",
            ">         x = x + self.sa(x) ##-- add residual connection\n",
            ">         x = x + self.ffwd(x) ##-- add residual connection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "! python bigram_v7.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOrZkcl4E-mZ",
        "outputId": "891b5766-24e4-43a1-d096-a272fdb78862"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.6208, val loss 4.6182\n",
            "step 500: train loss 2.3855, val loss 2.3836\n",
            "step 1000: train loss 2.2681, val loss 2.2638\n",
            "step 1500: train loss 2.1911, val loss 2.2064\n",
            "step 2000: train loss 2.1506, val loss 2.1866\n",
            "step 2500: train loss 2.1001, val loss 2.1436\n",
            "step 3000: train loss 2.0745, val loss 2.1436\n",
            "step 3500: train loss 2.0583, val loss 2.1167\n",
            "step 4000: train loss 2.0274, val loss 2.1081\n",
            "step 4500: train loss 2.0051, val loss 2.1078\n",
            "\n",
            "And they bridcewill, is by be madise, bube a enave Our my dalled\n",
            "here'd this us comen. Warderlascanessway, my fearstard, onour\n",
            "You, proof is hear this now\n",
            "Whime misters, hand latist in ov the and the now on you meselvinnce, all thus would by prup; and all, ye will, she rookes, a down'd\n",
            "the the to kelloal---on her eviby, with to must and hipence poocter,-for und kind thrupt for ar igner must with ale of wafife\n",
            "Rere my of.\n",
            "\n",
            "HENNS:\n",
            "Hast you as\n",
            "ardsal the age stavein cour aar tey it his chan you!\n",
            "An\n",
            "CPU times: user 625 ms, sys: 99.5 ms, total: 725 ms\n",
            "Wall time: 2min 7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LayerNorm\n",
        "\n",
        "LayerNorm (Layer Normalization) - это метод нормализации данных, который применяется в нейронных сетях для ускорения обучения и повышения стабильности сходимости.\n",
        "\n",
        "В отличие от Batch Normalization, который выполняет нормализацию по батчу, LayerNorm нормализует данные по каждому нейрону в слое. Таким образом, LayerNorm не зависит от размера батча и может быть использован для обработки данных в режиме онлайн.\n",
        "\n",
        "Формально, LayerNorm применяет нормализацию к входным данным $x$ по среднему значению $\\mu$ и стандартному отклонению $\\sigma$ по каждому признаку (нейрону) внутри слоя:\n",
        "\n",
        "\n",
        "$\\text{LayerNorm}(x_i) = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\odot \\gamma + \\beta$\n",
        "\n",
        "где $\\epsilon$ - это малое число, добавленное для стабильности вычислений, $\\gamma$ и $\\beta$ - это обучаемые параметры, которые могут быть использованы для регулирования масштаба и смещения данных после нормализации.\n",
        "\n",
        "Применение LayerNorm позволяет уменьшить внутреннюю зависимость между параметрами и ускорить сходимость при обучении нейронных сетей."
      ],
      "metadata": {
        "id": "aPglkTRiQAml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm:\n",
        "\n",
        "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "        self.eps = eps\n",
        "        self.gamma = torch.ones(dim)\n",
        "        self.beta = torch.zeros(dim)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        ##-- calculate the forward pass\n",
        "        xmean = x.mean(1, keepdim=True) ##-- mean by row\n",
        "        xvar = x.var(1, keepdim=True)\n",
        "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) ##-- normalize\n",
        "        self.out = self.gamma * xhat + self.beta\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.gamma, self.beta]\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "module = LayerNorm(100)\n",
        "x = torch.randn(32, 100)\n",
        "x = module(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJkdZbymHBsj",
        "outputId": "14c92b8e-3d4e-4927-baa8-35764025bfa9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.mean(1), x.var(1) ##-- по строке среднее равно нулю и СКО = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AscLc4t0Soz1",
        "outputId": "6b2a3247-3365-4df0-8698-3297e73394f1"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-9.5367e-09, -2.3842e-09, -2.0266e-08,  1.7881e-08,  1.6689e-08,\n",
              "          9.8348e-09,  4.7684e-09,  1.9073e-08, -1.4305e-08, -4.7684e-09,\n",
              "         -1.3113e-08, -5.9605e-09,  0.0000e+00, -7.1526e-09, -2.0266e-08,\n",
              "          7.0035e-09, -1.2815e-08,  1.7881e-08,  6.5565e-09, -4.7684e-09,\n",
              "          9.5367e-09, -3.5763e-09, -2.8610e-08,  4.7684e-09,  3.5763e-09,\n",
              "         -7.1526e-09, -4.7684e-09,  0.0000e+00,  5.3644e-09, -1.1921e-08,\n",
              "          4.7684e-09,  1.9073e-08]),\n",
              " tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000]))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.mean(0), x.var(0) ##-- по столбцам - нет"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjoJOyv6So_F",
        "outputId": "e0d8f9b9-94a0-49cb-ff05-98aa832c14ca"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.1469, -0.5910, -0.3974,  0.0468, -0.1431,  0.0138, -0.2664,  0.4181,\n",
              "          0.1426,  0.2191,  0.2554, -0.2625, -0.0543, -0.1050,  0.1541,  0.2492,\n",
              "          0.2498,  0.1354, -0.2027, -0.3772,  0.2920,  0.1959, -0.2249, -0.0574,\n",
              "          0.1293, -0.1413,  0.1445, -0.2509,  0.1434,  0.0128,  0.0631, -0.2482,\n",
              "         -0.0977,  0.0945,  0.1880,  0.0951,  0.0047,  0.2833,  0.1154, -0.3063,\n",
              "          0.0510,  0.1602,  0.0598,  0.1157,  0.0083, -0.2541, -0.0447, -0.0921,\n",
              "          0.1891, -0.0150, -0.1857, -0.4513, -0.1106,  0.0320,  0.0417,  0.1272,\n",
              "         -0.3022, -0.2864,  0.2507, -0.1101,  0.0402,  0.2277,  0.2753,  0.2577,\n",
              "         -0.1698,  0.2775, -0.1854,  0.0767, -0.2023,  0.2106,  0.1443,  0.1391,\n",
              "          0.1628,  0.1442, -0.0223, -0.0108,  0.0173,  0.0508, -0.0126,  0.1257,\n",
              "          0.0073,  0.0803, -0.0412,  0.0335, -0.2576, -0.0642, -0.1877, -0.1026,\n",
              "         -0.0888,  0.1562,  0.1422,  0.0295,  0.1925, -0.2169, -0.1416,  0.1693,\n",
              "         -0.1704, -0.2708,  0.1440, -0.2105]),\n",
              " tensor([0.7750, 0.8010, 1.0212, 0.6593, 0.7020, 0.7705, 0.8111, 1.0488, 0.7893,\n",
              "         0.9721, 1.0592, 1.1930, 0.7990, 0.7836, 1.4800, 0.9321, 1.0645, 0.9579,\n",
              "         1.1204, 1.2060, 1.2895, 1.2111, 1.3399, 1.2527, 0.5629, 0.9329, 0.8638,\n",
              "         0.8202, 0.7409, 0.9073, 0.6947, 0.9225, 1.0214, 0.8388, 1.0952, 1.1081,\n",
              "         0.9814, 1.4911, 0.7102, 0.5835, 1.4065, 0.8246, 1.0754, 1.0487, 1.3689,\n",
              "         0.7204, 0.6326, 0.7907, 0.6898, 1.2327, 1.4188, 1.0354, 1.1224, 0.8902,\n",
              "         1.4052, 1.2285, 0.8262, 1.3057, 0.7848, 1.0441, 0.8647, 0.8747, 0.9705,\n",
              "         0.7692, 1.0555, 1.0571, 1.3661, 0.9337, 0.8765, 0.9349, 0.9436, 1.1385,\n",
              "         0.8011, 0.9315, 0.9196, 0.7556, 1.2151, 0.6197, 0.8074, 1.3431, 1.1809,\n",
              "         1.3018, 1.0412, 2.0003, 0.7606, 0.8485, 1.1225, 1.0203, 0.7924, 0.9501,\n",
              "         1.0268, 0.6639, 1.0547, 0.8368, 0.5968, 1.0215, 0.8382, 1.3112, 0.7800,\n",
              "         0.8963]))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title bigram_v8\n",
        "bigram_v8 = \\\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "##-- hyperparameters\n",
        "batch_size = 32 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
        "block_size = 8 ##-- максимальная длина предложения (в нашем случае, количество символов)\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 32 ##-- размер эмбединга\n",
        "##------------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# here all the unique character that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "##-- create mapping from characters to integers\n",
        "stoi = { ch: i for i, ch in enumerate(chars) }\n",
        "atoi = { i: ch for i, ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([atoi[i] for i in l])\n",
        "\n",
        "##-- Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "##-- data loading\n",
        "def get_batch(split: str='train'):\n",
        "    '''\n",
        "    generate a small batch of data of inputs x and targets y\n",
        "\n",
        "    split: str: train or test\n",
        "    '''\n",
        "    data = train_data if split=='train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size, )) ##-- random idx\n",
        "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return (x, y)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    ''' one head of self-attention '''\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x) # (B, T, C)\n",
        "        k = self.key(x) # (B, T, C)\n",
        "        ##-- compute attention score 'affinities' (взаимоотношения между токенами)\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5 # (B, T, C) @ (B, C, T) -->> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        # perform the weighted aggregation of the value\n",
        "        v = self.value(x) # (B, T, C)\n",
        "        out = wei @ v  # (B, T, T) @ (B, T, C) -->> (B, T, C)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    ''' multiple heads of self-attention in parallel '''\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd) ##-- for residual connection\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) ##-- объединение по каналам\n",
        "        out = self.proj(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    ''' a simple linear layer followed by a non-linearity '''\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd) ##-- for residual connection\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    ''' Transformer block: communication followed by computation '''\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd) ##-- Layer Normalization by token (aka embedding)\n",
        "        self.ln2 = nn.LayerNorm(n_embd) ##-- Layer Normalization by token (aka embedding)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x)) ##-- add residual connection ##-- and layer norm token\n",
        "        x = x + self.ffwd(self.ln2(x)) ##-- add residual connection  ##-- and layer norm token\n",
        "        return x\n",
        "\n",
        "\n",
        "##-- super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ##-- each token directly read oof the logits for the next token from a lookip table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) ##-- берем эмбединг токена (кодируем токен)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd) ##-- кодируем позицию токена\n",
        "        self.blocks = nn.Sequential(\n",
        "            Block(n_embd, n_head=4),\n",
        "            Block(n_embd, n_head=4),\n",
        "            Block(n_embd, n_head=4),\n",
        "            nn.LayerNorm(n_embd),\n",
        "        ) ##-- MultiheadAttention -> FFN 3 times\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size) ##-- linear_model head\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        ##-- idx and targets are both (B, T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B, T, C) #-- (4, 8, 32), (batch_size, block_size, emb_size)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C) (8, 32) ##-- кодируем позицию токена\n",
        "        x = tok_emb + pos_emb ##-- (B, T, C) эмбединг токена и его позиции\n",
        "        x = self.blocks(x) ##-- apply 4 heads of self-attention (B, T, C)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size) #-- (4, 8, 65), (batch_size, block_size, vocab_size)\n",
        "        # print(logits.shape) # (4, 8, 65)\n",
        "        # print(targets.shape) # (4, 8)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            ##-- из батча размером 4 предложения переводим в одну строку (то есть четыре предложения в одно)\n",
        "            logits = logits.view(B*T, C)\n",
        "            ##-- второй вариант, таргеты в таком случае тоже не менять\n",
        "            # logits = torch.permute(logits, (0, 2, 1))\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens: int=100):\n",
        "        ##-- idx is the (B, T) array of the indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            ##-- crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            ##-- get the predictions\n",
        "            logits, _ = self(idx_cond)\n",
        "            ##-- focus only on the last time step (последнюю букву)\n",
        "            # print(f\"logits_before ={logits}, {logits.shape}\")\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # print(f\"logits_after ={logits}, {logits.shape}\")\n",
        "            ##-- softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # print(probs)\n",
        "            ##-- sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # print(idx_next)\n",
        "            ##-- append sampled idx to the running sample\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "\n",
        "##-- pytorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "\n",
        "##-- fit\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    ##-- sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    ##-- evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "##-- generate the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BUUz41IWS88n",
        "cellView": "form"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILENAME = 'bigram_v8.py'\n",
        "save(bigram_v8, FILENAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIrzO9CyVZE_",
        "outputId": "04d2ab5f-2285-4496-e298-1e2713551605"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved file at: /content/bigram_v8.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! diff bigram_v7.py bigram_v8.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGqMLzn6Wrah",
        "outputId": "2c3fc0f4-4f24-4b6a-9ee1-e60d0d2a1719"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2,3d1\n",
            "< \n",
            "< \n",
            "129a128,129\n",
            ">         self.ln1 = nn.LayerNorm(n_embd) ##-- Layer Normalization by token (aka embedding)\n",
            ">         self.ln2 = nn.LayerNorm(n_embd) ##-- Layer Normalization by token (aka embedding)\n",
            "132,133c132,133\n",
            "<         x = x + self.sa(x) ##-- add residual connection\n",
            "<         x = x + self.ffwd(x) ##-- add residual connection\n",
            "---\n",
            ">         x = x + self.sa(self.ln1(x)) ##-- add residual connection ##-- and layer norm token\n",
            ">         x = x + self.ffwd(self.ln2(x)) ##-- add residual connection  ##-- and layer norm token\n",
            "147a148\n",
            ">             nn.LayerNorm(n_embd),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "! python bigram_v8.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km4rcVbdVdOT",
        "outputId": "c1c1d576-2731-4148-e9b4-396cdf6cc507"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.3090, val loss 4.3083\n",
            "step 500: train loss 2.3978, val loss 2.3985\n",
            "step 1000: train loss 2.2651, val loss 2.2666\n",
            "step 1500: train loss 2.1693, val loss 2.1893\n",
            "step 2000: train loss 2.1301, val loss 2.1659\n",
            "step 2500: train loss 2.0830, val loss 2.1305\n",
            "step 3000: train loss 2.0505, val loss 2.1223\n",
            "step 3500: train loss 2.0406, val loss 2.0994\n",
            "step 4000: train loss 2.0137, val loss 2.0933\n",
            "step 4500: train loss 1.9909, val loss 2.0895\n",
            "\n",
            "And they bridce.\n",
            "\n",
            "STAULOLET:\n",
            "KING Proke? you eyarth the the gatals!\n",
            "You that us croce. Wardetlascauesswick, you,\n",
            "Dot comzorous\n",
            "Yours, to fitie bet milend liblees if ensent, will is that Grose,\n",
            "Be the now on you muselfinnd teal.\n",
            "-hus wouch by prup; and plow you lord.\n",
            "In amopeselaves\n",
            "Momery would thake on in on her piibse to they srive cenchimed though\n",
            "And strume kind thrupted so;\n",
            "Angied must with ale of whith Prive my of that but\n",
            "Hartioblisa\n",
            "Sadaad the Ereford:\n",
            "Go cour aar tey vry to chan you!\n",
            "My\n",
            "CPU times: user 660 ms, sys: 114 ms, total: 774 ms\n",
            "Wall time: 2min 19s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scale up\n",
        "\n",
        "Улучшение параметров модели"
      ],
      "metadata": {
        "id": "VwlNERn3VgLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title bigram_v9\n",
        "bigram_v9 = \\\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "##-- hyperparameters\n",
        "batch_size = 64 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
        "block_size = 256 ##-- максимальная длина предложения (в нашем случае, количество символов)\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 384 ##-- размер эмбединга\n",
        "n_head = 6 ##-- количество голов в multihead attention\n",
        "n_layer = 6 ##-- количество блоков\n",
        "dropout = 0.2\n",
        "##------------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# here all the unique character that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "##-- create mapping from characters to integers\n",
        "stoi = { ch: i for i, ch in enumerate(chars) }\n",
        "atoi = { i: ch for i, ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([atoi[i] for i in l])\n",
        "\n",
        "##-- Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "##-- data loading\n",
        "def get_batch(split: str='train'):\n",
        "    '''\n",
        "    generate a small batch of data of inputs x and targets y\n",
        "\n",
        "    split: str: train or test\n",
        "    '''\n",
        "    data = train_data if split=='train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size, )) ##-- random idx\n",
        "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return (x, y)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    ''' one head of self-attention '''\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x) # (B, T, C)\n",
        "        k = self.key(x) # (B, T, C)\n",
        "        ##-- compute attention score 'affinities' (взаимоотношения между токенами)\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5 # (B, T, C) @ (B, C, T) -->> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei) ##-- некоторые токены не будут взаимодействовать друг с другом\n",
        "        # perform the weighted aggregation of the value\n",
        "        v = self.value(x) # (B, T, C)\n",
        "        out = wei @ v  # (B, T, T) @ (B, T, C) -->> (B, T, C)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    ''' multiple heads of self-attention in parallel '''\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd) ##-- for residual connection\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) ##-- объединение по каналам\n",
        "        out = self.proj(out)\n",
        "        out = self.dropout(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    ''' a simple linear layer followed by a non-linearity '''\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd), ##-- for residual connection\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    ''' Transformer block: communication followed by computation '''\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd) ##-- Layer Normalization by token (aka embedding)\n",
        "        self.ln2 = nn.LayerNorm(n_embd) ##-- Layer Normalization by token (aka embedding)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x)) ##-- add residual connection ##-- and layer norm token\n",
        "        x = x + self.ffwd(self.ln2(x)) ##-- add residual connection  ##-- and layer norm token\n",
        "        return x\n",
        "\n",
        "\n",
        "##-- super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ##-- each token directly read oof the logits for the next token from a lookip table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) ##-- берем эмбединг токена (кодируем токен)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd) ##-- кодируем позицию токена\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)]) ##-- MHA and FFWN n_layer times\n",
        "        self.ln_f = nn.LayerNorm(n_embd) ##-- final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size) ##-- linear_model head\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        ##-- idx and targets are both (B, T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B, T, C) #-- (4, 8, 32), (batch_size, block_size, emb_size)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C) (8, 32) ##-- кодируем позицию токена\n",
        "        x = tok_emb + pos_emb ##-- (B, T, C) эмбединг токена и его позиции\n",
        "        x = self.blocks(x) ##-- apply 4 heads of self-attention (B, T, C)\n",
        "        x = self.ln_f(x) # (B, T, C)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size) #-- (4, 8, 65), (batch_size, block_size, vocab_size)\n",
        "        # print(logits.shape) # (4, 8, 65)\n",
        "        # print(targets.shape) # (4, 8)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            ##-- из батча размером 4 предложения переводим в одну строку (то есть четыре предложения в одно)\n",
        "            logits = logits.view(B*T, C)\n",
        "            ##-- второй вариант, таргеты в таком случае тоже не менять\n",
        "            # logits = torch.permute(logits, (0, 2, 1))\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens: int=100):\n",
        "        ##-- idx is the (B, T) array of the indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            ##-- crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            ##-- get the predictions\n",
        "            logits, _ = self(idx_cond)\n",
        "            ##-- focus only on the last time step (последнюю букву)\n",
        "            # print(f\"logits_before ={logits}, {logits.shape}\")\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # print(f\"logits_after ={logits}, {logits.shape}\")\n",
        "            ##-- softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # print(probs)\n",
        "            ##-- sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # print(idx_next)\n",
        "            ##-- append sampled idx to the running sample\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "\n",
        "##-- pytorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "\n",
        "##-- fit\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    ##-- sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    ##-- evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "##-- generate the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "owZrICN0Wgyq",
        "cellView": "form"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILENAME = 'bigram_v9.py'\n",
        "save(bigram_v9, FILENAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA-xjgQzYjEO",
        "outputId": "9c8f8c40-0c7e-4753-8924-716a2c47386c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved file at: /content/bigram_v9.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! diff bigram_v8.py bigram_v9.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGdn9sciYqDW",
        "outputId": "32f00916-6464-472a-8e39-d577284a9b17"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7,8c7,8\n",
            "< batch_size = 32 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
            "< block_size = 8 ##-- максимальная длина предложения (в нашем случае, количество символов)\n",
            "---\n",
            "> batch_size = 64 ##-- сколько независимых объектов (предложений) обрабатывается за раз (параллельно)\n",
            "> block_size = 256 ##-- максимальная длина предложения (в нашем случае, количество символов)\n",
            "11c11\n",
            "< learning_rate = 1e-3\n",
            "---\n",
            "> learning_rate = 3e-4\n",
            "14c14,17\n",
            "< n_embd = 32 ##-- размер эмбединга\n",
            "---\n",
            "> n_embd = 384 ##-- размер эмбединга\n",
            "> n_head = 6 ##-- количество голов в multihead attention\n",
            "> n_layer = 6 ##-- количество блоков\n",
            "> dropout = 0.2\n",
            "76a80,81\n",
            ">         self.dropout = nn.Dropout(dropout)\n",
            "> \n",
            "84a90\n",
            ">         wei = self.dropout(wei) ##-- некоторые токены не будут взаимодействовать друг с другом\n",
            "97a104\n",
            ">         self.dropout = nn.Dropout(dropout)\n",
            "101a109\n",
            ">         out = self.dropout(out)\n",
            "113c121,122\n",
            "<             nn.Linear(4 * n_embd, n_embd) ##-- for residual connection\n",
            "---\n",
            ">             nn.Linear(4 * n_embd, n_embd), ##-- for residual connection\n",
            ">             nn.Dropout(dropout),\n",
            "144,149c153,154\n",
            "<         self.blocks = nn.Sequential(\n",
            "<             Block(n_embd, n_head=4),\n",
            "<             Block(n_embd, n_head=4),\n",
            "<             Block(n_embd, n_head=4),\n",
            "<             nn.LayerNorm(n_embd),\n",
            "<         ) ##-- MultiheadAttention -> FFN 3 times\n",
            "---\n",
            ">         self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)]) ##-- MHA and FFWN n_layer times\n",
            ">         self.ln_f = nn.LayerNorm(n_embd) ##-- final layer norm\n",
            "159a165\n",
            ">         x = self.ln_f(x) # (B, T, C)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "! python bigram_v9.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyPAkq7SYmdY",
        "outputId": "420ad0b8-d154-45fb-8454-cf00aeeb9d7d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.2849, val loss 4.2824\n",
            "step 500: train loss 1.6788, val loss 1.8442\n",
            "step 1000: train loss 1.3603, val loss 1.5854\n",
            "step 1500: train loss 1.2405, val loss 1.5051\n",
            "step 2000: train loss 1.1581, val loss 1.4841\n",
            "step 2500: train loss 1.0912, val loss 1.4882\n",
            "step 3000: train loss 1.0312, val loss 1.4934\n",
            "step 3500: train loss 0.9698, val loss 1.5189\n",
            "step 4000: train loss 0.9121, val loss 1.5430\n",
            "step 4500: train loss 0.8506, val loss 1.5726\n",
            "\n",
            "Good night! How like to him?\n",
            "\n",
            "GLOUCESTER:\n",
            "Bress them for their father's moistress apace?\n",
            "Alack, haste their within tender pines\n",
            "I tread upon thee! Tread such a sad stars,\n",
            "That, when the tiger new shades metimes, ere now\n",
            "show nine to triumphs: but stinato, bawd?\n",
            "Past noise, to quench:\n",
            "All then all moons martings, were unto me,\n",
            "Thou and mere at fierces or own to love.\n",
            "\n",
            "KING RICHARD II:\n",
            "Lay aside in banishhood stark what now haste?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Go, go, bear me; I will bear read till lo.\n",
            "I mean\n",
            "CPU times: user 4.92 s, sys: 776 ms, total: 5.7 s\n",
            "Wall time: 16min 54s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e0B16Lm1Yyd2"
      },
      "execution_count": 75,
      "outputs": []
    }
  ]
}
